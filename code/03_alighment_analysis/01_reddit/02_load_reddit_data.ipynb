{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit Scraping\n",
    "Documentation reference: https://praw.readthedocs.io/en/stable/\n",
    "This script scrapes the top 20 Reddit posts for each target skincare brand and retrieves the top 10 comments from each post. The collected data forms the basis for alignment analyses on reddit. \n",
    "\n",
    "\n",
    "The following brands were selected as targets for analysis:\n",
    "\n",
    "- `Estée Lauder`\n",
    "- `Fenty Beauty`\n",
    "- `Fenty`\n",
    "- `e.l.f. Cosmetics`\n",
    "- `e.l.f.`\n",
    "- `elf`\n",
    "- `Tarte Cosmetics`\n",
    "- `Tarte`\n",
    "- `Glossier`\n",
    "- `Laneige`\n",
    "- `Sulwhasoo`\n",
    "- `Etude House`\n",
    "- `Etude`\n",
    "- `Innisfree`\n",
    "- `COSRX`\n",
    "\n",
    "\n",
    "\n",
    "Data was collected from the following skincare-related subreddits:\n",
    "\n",
    "- `SkincareAddiction`\n",
    "- `Sephora`\n",
    "- `Blackskincare`\n",
    "- `AsianBeauty`\n",
    "- `KoreanBeauty`\n",
    "- `BrownBeauty`\n",
    "- `IndianSkincareAddicts`\n",
    "\n",
    "The following fields are collected for each Reddit post related to the target brand:\n",
    "\n",
    "- `subreddit_name`: Name of the subreddit the post is from  \n",
    "- `post_id`: Unique identifier for the post  \n",
    "- `title`: Title of the Reddit post  \n",
    "- `description`: Body text of the post  \n",
    "- `score`: Total upvotes minus downvotes  \n",
    "- `num_comments`: Number of comments on the post  \n",
    "- `top_comments`: A list of the top comments extracted from the post  \n",
    "- `upvote_ratio`: Ratio of upvotes to total votes  \n",
    "- `brand`: The skincare brand associated with the post (based on the search query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import praw\n",
    "from praw.models import MoreComments\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import ast\n",
    "import re\n",
    "# Tools for text analysis\n",
    "# We can use nltk to extract adjective and verbs related to the product/brand \n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "# Vader sentiment analysis \n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from rapidfuzz import process, fuzz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "output_path = \"../../../data/alingment_analysis/reddit/\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape post from related subreddits\n",
    "This kinda takes forever, so maybe use the already loaded ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=os.getenv(\"REDDIT_CLIENT_ID\"),\n",
    "    client_secret=os.getenv(\"REDDIT_CLIENT_SECRET\"),\n",
    "    user_agent=os.getenv(\"REDDIT_USER_AGENT\"),\n",
    "    username=os.getenv(\"REDDIT_USERNAME\"),\n",
    ")\n",
    "\n",
    "subreddit_list = [\"SkincareAddiction\", \n",
    "                  \"Sephora\", \n",
    "                  \"Blackskincare\", \n",
    "                  \"AsianBeauty\", \n",
    "                  'KoreanBeauty',\n",
    "                  'BrownBeauty',\n",
    "                  \"IndianSkincareAddicts\", \n",
    "                  ]\n",
    "\n",
    "all_posts = []\n",
    "\n",
    "# get the top 20 post from each subreddit (don't know rate limit so 20 for now)\n",
    "# Documentation: https://praw.readthedocs.io/en/stable/code_overview/models/subreddit.html\n",
    "# added some more name variation to the search query \n",
    "\n",
    "target_brands = [\n",
    "'Estée Lauder',\n",
    "'Fenty Beauty',\n",
    "'Fenty',\n",
    "'e.l.f. Cosmetics',\n",
    "'e.l.f.',\n",
    "'elf',\n",
    "'Tarte Cosmetics',\n",
    "'Tarte',\n",
    "'Glossier',\n",
    "'Laneige',\n",
    "'Sulwhasoo',\n",
    "'Etude House',\n",
    "'Etude',\n",
    "'Innisfree',\n",
    "'COSRX',\n",
    "]\n",
    "# Remove irrelevant comment made by bots \n",
    "def is_bot(author):\n",
    "    if author is None:\n",
    "        return True\n",
    "    name = author.name.lower()\n",
    "    return \"bot\" in name or name == \"automoderator\"\n",
    "\n",
    "# Match by header title (should I go more in depth here?)\n",
    "def brand_word_match(text, brand_list):\n",
    "    match = process.extractOne(text, brand_list, scorer=fuzz.partial_ratio)\n",
    "    if match and match[1] > 85:\n",
    "        return match[0]\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_top_comments(post):\n",
    "\n",
    "    post.comments.replace_more(limit=0)  \n",
    "\n",
    "    top_comments = []\n",
    "    for comment in post.comments:\n",
    "        if isinstance(comment, MoreComments):\n",
    "            continue \n",
    "        if is_bot(comment.author):\n",
    "            continue\n",
    "        if comment.body.strip().lower() in [\"[deleted]\", \"[removed]\"]:\n",
    "            continue \n",
    "        top_comments.append(comment.body.strip())\n",
    "        if len(top_comments) == 10:\n",
    "            break\n",
    "    return top_comments\n",
    "\n",
    "\n",
    "# Product Question and Review are specific to skincareaddiction to pull more relevant post, but '' can be used for other subreddits\n",
    "reddit_tags = ['[Product Question]', '[Review]', '']\n",
    "# Filter out duplicate posts \n",
    "post_seen = {}\n",
    "for sub in subreddit_list:\n",
    "    try:\n",
    "        for brand in target_brands:\n",
    "            for tag in reddit_tags:\n",
    "                query = f'\"{tag} {brand}\"'\n",
    "                post_collection = reddit.subreddit(sub).search(query.lower(), limit=20, sort=\"relevance\")\n",
    "                for post in post_collection: \n",
    "                    # Filter out duplicate posts \n",
    "                    if post.id in post_seen:\n",
    "                        continue \n",
    "                    is_match = brand_word_match(post.title, target_brands)\n",
    "                    if is_match:\n",
    "                        top_comments = get_top_comments(post)\n",
    "                        all_posts.append({\n",
    "                        \"subreddit_name\": sub,\n",
    "                        \"post_id\": post.id,\n",
    "                        \"title\": post.title,\n",
    "                        \"description\": post.selftext,\n",
    "                        \"score\": post.score,\n",
    "                        \"num_comments\": post.num_comments,\n",
    "                        \"top_comments\": top_comments,\n",
    "                        \"upvote_ratio\": post.upvote_ratio,\n",
    "                        \"brand\": brand\n",
    "                    })\n",
    "                    # mark post as seen\n",
    "                    post_seen[post.id] = True\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {sub}: {e}\")\n",
    "        continue\n",
    "    \n",
    "subreddit_df = pd.DataFrame(all_posts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit_name</th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>top_comments</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>1bv7f30</td>\n",
       "      <td>[Product Question] Estée Lauder ANR - Allergic</td>\n",
       "      <td>Anyone have idea what could be best use of thi...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[Return it? Give it to someone?, You can try t...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Estée Lauder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>psd79w</td>\n",
       "      <td>[Product Question] Estée Lauder Advanced Night...</td>\n",
       "      <td>So I have started my first bottle of this seru...</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>[I've used this serum for years and it's one o...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Estée Lauder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>wly2yu</td>\n",
       "      <td>[Product Question] Estée Lauder night repair s...</td>\n",
       "      <td>I have a coupon for a free sample and I’m thin...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[I absolutely love it and I've used it for yea...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Estée Lauder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>cszttj</td>\n",
       "      <td>[product question] Estée Lauder Advanced Night...</td>\n",
       "      <td>alot good Reviews is worth HYPE ?\\n\\n4.9/5 292...</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>[Nope! I am lucky that my sister works in the ...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Estée Lauder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>lx8cl1</td>\n",
       "      <td>[product question] Estée Lauder ANR smell</td>\n",
       "      <td>I have a couple of sample bottles of Estée Lau...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>[A few *years* old?\\n\\nYeah, dump that., You d...</td>\n",
       "      <td>0.81</td>\n",
       "      <td>Estée Lauder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subreddit_name  post_id  \\\n",
       "0  SkincareAddiction  1bv7f30   \n",
       "1  SkincareAddiction   psd79w   \n",
       "2  SkincareAddiction   wly2yu   \n",
       "3  SkincareAddiction   cszttj   \n",
       "4  SkincareAddiction   lx8cl1   \n",
       "\n",
       "                                               title  \\\n",
       "0     [Product Question] Estée Lauder ANR - Allergic   \n",
       "1  [Product Question] Estée Lauder Advanced Night...   \n",
       "2  [Product Question] Estée Lauder night repair s...   \n",
       "3  [product question] Estée Lauder Advanced Night...   \n",
       "4          [product question] Estée Lauder ANR smell   \n",
       "\n",
       "                                         description  score  num_comments  \\\n",
       "0  Anyone have idea what could be best use of thi...      3             4   \n",
       "1  So I have started my first bottle of this seru...      7            24   \n",
       "2  I have a coupon for a free sample and I’m thin...      3             4   \n",
       "3  alot good Reviews is worth HYPE ?\\n\\n4.9/5 292...     13            12   \n",
       "4  I have a couple of sample bottles of Estée Lau...      3             5   \n",
       "\n",
       "                                        top_comments  upvote_ratio  \\\n",
       "0  [Return it? Give it to someone?, You can try t...          1.00   \n",
       "1  [I've used this serum for years and it's one o...          1.00   \n",
       "2  [I absolutely love it and I've used it for yea...          1.00   \n",
       "3  [Nope! I am lucky that my sister works in the ...          1.00   \n",
       "4  [A few *years* old?\\n\\nYeah, dump that., You d...          0.81   \n",
       "\n",
       "          brand  \n",
       "0  Estée Lauder  \n",
       "1  Estée Lauder  \n",
       "2  Estée Lauder  \n",
       "3  Estée Lauder  \n",
       "4  Estée Lauder  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Raw subreddit data \n",
    "subreddit_df.to_csv(output_path + \"subreddit_data.csv\", index=False)\n",
    "subreddit_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qss-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
