{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit Scraping\n",
    "Documentation reference: https://praw.readthedocs.io/en/stable/\n",
    "This script scrapes the top 20 Reddit posts for each target skincare brand and retrieves the top 10 comments from each post. The collected data forms the basis for alignment analyses on reddit. \n",
    "\n",
    "\n",
    "The following brands were selected as targets for analysis:\n",
    "\n",
    "- `Estée Lauder`\n",
    "- `Fenty Beauty`\n",
    "- `Fenty`\n",
    "- `e.l.f. Cosmetics`\n",
    "- `e.l.f.`\n",
    "- `elf`\n",
    "- `Tarte Cosmetics`\n",
    "- `Tarte`\n",
    "- `Glossier`\n",
    "- `Laneige`\n",
    "- `Sulwhasoo`\n",
    "- `Etude House`\n",
    "- `Etude`\n",
    "- `Innisfree`\n",
    "- `COSRX`\n",
    "\n",
    "\n",
    "\n",
    "Data was collected from the following skincare-related subreddits:\n",
    "\n",
    "- `SkincareAddiction`\n",
    "- `Sephora`\n",
    "- `Blackskincare`\n",
    "- `AsianBeauty`\n",
    "- `KoreanBeauty`\n",
    "- `BrownBeauty`\n",
    "- `IndianSkincareAddicts`\n",
    "\n",
    "The following fields are collected for each Reddit post related to the target brand:\n",
    "\n",
    "- `subreddit_name`: Name of the subreddit the post is from  \n",
    "- `post_id`: Unique identifier for the post  \n",
    "- `title`: Title of the Reddit post  \n",
    "- `description`: Body text of the post  \n",
    "- `score`: Total upvotes minus downvotes  \n",
    "- `num_comments`: Number of comments on the post  \n",
    "- `top_comments`: A list of the top comments extracted from the post  \n",
    "- `upvote_ratio`: Ratio of upvotes to total votes  \n",
    "- `brand`: The skincare brand associated with the post (based on the search query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import praw\n",
    "from praw.models import MoreComments\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import ast\n",
    "import re\n",
    "# Tools for text analysis\n",
    "# We can use nltk to extract adjective and verbs related to the product/brand \n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "# Vader sentiment analysis \n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from rapidfuzz import process, fuzz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "output_path = \"../../../data/alingment_analysis/reddit/\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape post from related subreddits\n",
    "This kinda takes forever, so maybe use the already loaded ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=os.getenv(\"REDDIT_CLIENT_ID\"),\n",
    "    client_secret=os.getenv(\"REDDIT_CLIENT_SECRET\"),\n",
    "    user_agent=os.getenv(\"REDDIT_USER_AGENT\"),\n",
    "    username=os.getenv(\"REDDIT_USERNAME\"),\n",
    ")\n",
    "\n",
    "subreddit_list = [\"SkincareAddiction\", \n",
    "                  \"Sephora\", \n",
    "                  \"Blackskincare\", \n",
    "                  \"AsianBeauty\", \n",
    "                  'KoreanBeauty',\n",
    "                  'BrownBeauty',\n",
    "                  \"IndianSkincareAddicts\", \n",
    "                  ]\n",
    "\n",
    "all_posts = []\n",
    "\n",
    "# get the top 20 post from each subreddit (don't know rate limit so 20 for now)\n",
    "# Documentation: https://praw.readthedocs.io/en/stable/code_overview/models/subreddit.html\n",
    "# added some more name variation to the search query \n",
    "\n",
    "target_brands = [\n",
    "'Estée Lauder',\n",
    "'Fenty Beauty',\n",
    "'Fenty',\n",
    "'e.l.f. Cosmetics',\n",
    "'e.l.f.',\n",
    "'elf',\n",
    "'Tarte Cosmetics',\n",
    "'Tarte',\n",
    "'Glossier',\n",
    "'Laneige',\n",
    "'Sulwhasoo',\n",
    "'Etude House',\n",
    "'Etude',\n",
    "'Innisfree',\n",
    "'COSRX',\n",
    "]\n",
    "five_years_ago = datetime.utcnow() - timedelta(days=5*365)\n",
    "# Remove irrelevant comment made by bots \n",
    "def is_bot(author):\n",
    "    if author is None:\n",
    "        return True\n",
    "    name = author.name.lower()\n",
    "    return \"bot\" in name or name == \"automoderator\"\n",
    "\n",
    "# Match by header title (should I go more in depth here?)\n",
    "def brand_word_match(text, brand_list):\n",
    "    match = process.extractOne(text, brand_list, scorer=fuzz.partial_ratio)\n",
    "    if match and match[1] > 85:\n",
    "        return match[0]\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_top_comments(post):\n",
    "\n",
    "    post.comments.replace_more(limit=0)  \n",
    "\n",
    "    top_comments = []\n",
    "    for comment in post.comments:\n",
    "        if isinstance(comment, MoreComments):\n",
    "            continue \n",
    "        if is_bot(comment.author):\n",
    "            continue\n",
    "        if comment.body.strip().lower() in [\"[deleted]\", \"[removed]\"]:\n",
    "            continue \n",
    "        top_comments.append(comment.body.strip())\n",
    "        if len(top_comments) == 10:\n",
    "            break\n",
    "    return top_comments\n",
    "\n",
    "\n",
    "# Product Question and Review are specific to skincareaddiction to pull more relevant post, but '' can be used for other subreddits# qu\n",
    "reddit_tags = ['[Product Question]', '[Review]', '']\n",
    "\n",
    "# Filter out duplicate posts \n",
    "post_seen = {}\n",
    "for sub in subreddit_list:\n",
    "    try:\n",
    "        for brand in target_brands:\n",
    "            for tag in reddit_tags:\n",
    "                query = f'\"{tag} {brand}\"'\n",
    "                post_collection = reddit.subreddit(sub).search(query.lower(), limit=20, sort=\"relevance\", time_filter='all')\n",
    "                for post in post_collection: \n",
    "                    # Filter out duplicate posts \n",
    "                    if post.id in post_seen:\n",
    "                        continue \n",
    "                    # Filter out posts older than 5 years\n",
    "                    post_datetime = datetime.utcfromtimestamp(post.created_utc)\n",
    "                    if post_datetime < five_years_ago:\n",
    "                        continue\n",
    "                    \n",
    "                    is_match = brand_word_match(post.title, target_brands)\n",
    "                    if is_match:\n",
    "                        top_comments = get_top_comments(post)\n",
    "                        all_posts.append({\n",
    "                        \"subreddit_name\": sub,\n",
    "                        \"post_id\": post.id,\n",
    "                        \"title\": post.title,\n",
    "                        \"description\": post.selftext,\n",
    "                        \"score\": post.score,\n",
    "                        \"num_comments\": post.num_comments,\n",
    "                        \"top_comments\": top_comments,\n",
    "                        \"upvote_ratio\": post.upvote_ratio,\n",
    "                        \"brand\": brand\n",
    "                    })\n",
    "                    # mark post as seen\n",
    "                    post_seen[post.id] = True\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {sub}: {e}\")\n",
    "        continue\n",
    "    \n",
    "subreddit_df = pd.DataFrame(all_posts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit_name</th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>top_comments</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>1bv7f30</td>\n",
       "      <td>[Product Question] Estée Lauder ANR - Allergic</td>\n",
       "      <td>Anyone have idea what could be best use of thi...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[Return it? Give it to someone?, You can try t...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Estée Lauder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>psd79w</td>\n",
       "      <td>[Product Question] Estée Lauder Advanced Night...</td>\n",
       "      <td>So I have started my first bottle of this seru...</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>[I've used this serum for years and it's one o...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Estée Lauder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>wly2yu</td>\n",
       "      <td>[Product Question] Estée Lauder night repair s...</td>\n",
       "      <td>I have a coupon for a free sample and I’m thin...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[I absolutely love it and I've used it for yea...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Estée Lauder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>lx8cl1</td>\n",
       "      <td>[product question] Estée Lauder ANR smell</td>\n",
       "      <td>I have a couple of sample bottles of Estée Lau...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>[A few *years* old?\\n\\nYeah, dump that., You d...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Estée Lauder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>1i5q8th</td>\n",
       "      <td>[Product question] Dupe for Estée Lauder Advan...</td>\n",
       "      <td>I got this half off at Ulta based on the esthe...</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>[Missha time revolution night repair ampoule, ...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Estée Lauder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>IndianSkincareAddicts</td>\n",
       "      <td>1k9pf2e</td>\n",
       "      <td>COSRX AHA/BHA Clarifying Treatment Toner affec...</td>\n",
       "      <td>Its been 3 week and ive used this toner 3 to 4...</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>[I have this toner and I use it twice a week, ...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>COSRX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>IndianSkincareAddicts</td>\n",
       "      <td>1716cun</td>\n",
       "      <td>Fake COSRX Advanced Snail Mucin 92 All In One ...</td>\n",
       "      <td>I ordered my first cosrx advanced snail mucin ...</td>\n",
       "      <td>245</td>\n",
       "      <td>63</td>\n",
       "      <td>[For the nth time stop buying skincare  and ma...</td>\n",
       "      <td>0.97</td>\n",
       "      <td>COSRX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>IndianSkincareAddicts</td>\n",
       "      <td>1k5v4sc</td>\n",
       "      <td>Review of COSRX Snail Mucin Power Essence</td>\n",
       "      <td>I’ve been using the COSRX Snail Mucin Essence ...</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>[Can you please share your skin type ? And how...</td>\n",
       "      <td>0.90</td>\n",
       "      <td>COSRX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>IndianSkincareAddicts</td>\n",
       "      <td>1l5fgc6</td>\n",
       "      <td>COSRX from Myntra! Real or Fake?</td>\n",
       "      <td>Bought COSRX Aloe Soothing Suncream from Myntr...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>[I think myntra sells genuine products. I've o...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>COSRX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>IndianSkincareAddicts</td>\n",
       "      <td>1928sit</td>\n",
       "      <td>COSRX Advance Snail 96 Mucin Power Essence vs ...</td>\n",
       "      <td>Cosrx Advanced Snail 96 Mucin Power Essence (1...</td>\n",
       "      <td>45</td>\n",
       "      <td>55</td>\n",
       "      <td>[If you use snail mucin, you need a moisturise...</td>\n",
       "      <td>0.92</td>\n",
       "      <td>COSRX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>645 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            subreddit_name  post_id  \\\n",
       "0        SkincareAddiction  1bv7f30   \n",
       "1        SkincareAddiction   psd79w   \n",
       "2        SkincareAddiction   wly2yu   \n",
       "3        SkincareAddiction   lx8cl1   \n",
       "4        SkincareAddiction  1i5q8th   \n",
       "..                     ...      ...   \n",
       "640  IndianSkincareAddicts  1k9pf2e   \n",
       "641  IndianSkincareAddicts  1716cun   \n",
       "642  IndianSkincareAddicts  1k5v4sc   \n",
       "643  IndianSkincareAddicts  1l5fgc6   \n",
       "644  IndianSkincareAddicts  1928sit   \n",
       "\n",
       "                                                 title  \\\n",
       "0       [Product Question] Estée Lauder ANR - Allergic   \n",
       "1    [Product Question] Estée Lauder Advanced Night...   \n",
       "2    [Product Question] Estée Lauder night repair s...   \n",
       "3            [product question] Estée Lauder ANR smell   \n",
       "4    [Product question] Dupe for Estée Lauder Advan...   \n",
       "..                                                 ...   \n",
       "640  COSRX AHA/BHA Clarifying Treatment Toner affec...   \n",
       "641  Fake COSRX Advanced Snail Mucin 92 All In One ...   \n",
       "642          Review of COSRX Snail Mucin Power Essence   \n",
       "643                   COSRX from Myntra! Real or Fake?   \n",
       "644  COSRX Advance Snail 96 Mucin Power Essence vs ...   \n",
       "\n",
       "                                           description  score  num_comments  \\\n",
       "0    Anyone have idea what could be best use of thi...      3             4   \n",
       "1    So I have started my first bottle of this seru...      7            24   \n",
       "2    I have a coupon for a free sample and I’m thin...      3             4   \n",
       "3    I have a couple of sample bottles of Estée Lau...      4             5   \n",
       "4    I got this half off at Ulta based on the esthe...      8             7   \n",
       "..                                                 ...    ...           ...   \n",
       "640  Its been 3 week and ive used this toner 3 to 4...      7            28   \n",
       "641  I ordered my first cosrx advanced snail mucin ...    245            63   \n",
       "642  I’ve been using the COSRX Snail Mucin Essence ...      8            14   \n",
       "643  Bought COSRX Aloe Soothing Suncream from Myntr...      3             6   \n",
       "644  Cosrx Advanced Snail 96 Mucin Power Essence (1...     45            55   \n",
       "\n",
       "                                          top_comments  upvote_ratio  \\\n",
       "0    [Return it? Give it to someone?, You can try t...          1.00   \n",
       "1    [I've used this serum for years and it's one o...          1.00   \n",
       "2    [I absolutely love it and I've used it for yea...          1.00   \n",
       "3    [A few *years* old?\\n\\nYeah, dump that., You d...          1.00   \n",
       "4    [Missha time revolution night repair ampoule, ...          1.00   \n",
       "..                                                 ...           ...   \n",
       "640  [I have this toner and I use it twice a week, ...          1.00   \n",
       "641  [For the nth time stop buying skincare  and ma...          0.97   \n",
       "642  [Can you please share your skin type ? And how...          0.90   \n",
       "643  [I think myntra sells genuine products. I've o...          1.00   \n",
       "644  [If you use snail mucin, you need a moisturise...          0.92   \n",
       "\n",
       "            brand  \n",
       "0    Estée Lauder  \n",
       "1    Estée Lauder  \n",
       "2    Estée Lauder  \n",
       "3    Estée Lauder  \n",
       "4    Estée Lauder  \n",
       "..            ...  \n",
       "640         COSRX  \n",
       "641         COSRX  \n",
       "642         COSRX  \n",
       "643         COSRX  \n",
       "644         COSRX  \n",
       "\n",
       "[645 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Raw subreddit data \n",
    "subreddit_df.to_csv(output_path + \"subreddit_data.csv\", index=False)\n",
    "subreddit_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qss-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
