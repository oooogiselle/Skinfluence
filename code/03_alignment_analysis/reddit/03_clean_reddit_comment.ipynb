{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comment text cleaning \n",
    "1. Break each comment down into as a individual row \n",
    "2. Preprocess each row\n",
    "3. Export cleaned comment data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import re\n",
    "import ast\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "output_path = \"../../../data/alignment_analysis/\"\n",
    "os.makedirs(output_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Subreddit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit_name</th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>top_comments</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>1bv7f30</td>\n",
       "      <td>[Product Question] Estée Lauder ANR - Allergic</td>\n",
       "      <td>Anyone have idea what could be best use of thi...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>['Return it? Give it to someone?', 'You can tr...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Estée Lauder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>psd79w</td>\n",
       "      <td>[Product Question] Estée Lauder Advanced Night...</td>\n",
       "      <td>So I have started my first bottle of this seru...</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>[\"I've used this serum for years and it's one ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Estée Lauder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>wly2yu</td>\n",
       "      <td>[Product Question] Estée Lauder night repair s...</td>\n",
       "      <td>I have a coupon for a free sample and I’m thin...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[\"I absolutely love it and I've used it for ye...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Estée Lauder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>lx8cl1</td>\n",
       "      <td>[product question] Estée Lauder ANR smell</td>\n",
       "      <td>I have a couple of sample bottles of Estée Lau...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>['A few *years* old?\\n\\nYeah, dump that.', 'Yo...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Estée Lauder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>1i5q8th</td>\n",
       "      <td>[Product question] Dupe for Estée Lauder Advan...</td>\n",
       "      <td>I got this half off at Ulta based on the esthe...</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>['Missha time revolution night repair ampoule'...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Estée Lauder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subreddit_name  post_id  \\\n",
       "0  SkincareAddiction  1bv7f30   \n",
       "1  SkincareAddiction   psd79w   \n",
       "2  SkincareAddiction   wly2yu   \n",
       "3  SkincareAddiction   lx8cl1   \n",
       "4  SkincareAddiction  1i5q8th   \n",
       "\n",
       "                                               title  \\\n",
       "0     [Product Question] Estée Lauder ANR - Allergic   \n",
       "1  [Product Question] Estée Lauder Advanced Night...   \n",
       "2  [Product Question] Estée Lauder night repair s...   \n",
       "3          [product question] Estée Lauder ANR smell   \n",
       "4  [Product question] Dupe for Estée Lauder Advan...   \n",
       "\n",
       "                                         description  score  num_comments  \\\n",
       "0  Anyone have idea what could be best use of thi...      3             4   \n",
       "1  So I have started my first bottle of this seru...      7            24   \n",
       "2  I have a coupon for a free sample and I’m thin...      3             4   \n",
       "3  I have a couple of sample bottles of Estée Lau...      4             5   \n",
       "4  I got this half off at Ulta based on the esthe...      8             7   \n",
       "\n",
       "                                        top_comments  upvote_ratio  \\\n",
       "0  ['Return it? Give it to someone?', 'You can tr...           1.0   \n",
       "1  [\"I've used this serum for years and it's one ...           1.0   \n",
       "2  [\"I absolutely love it and I've used it for ye...           1.0   \n",
       "3  ['A few *years* old?\\n\\nYeah, dump that.', 'Yo...           1.0   \n",
       "4  ['Missha time revolution night repair ampoule'...           1.0   \n",
       "\n",
       "          brand  \n",
       "0  Estée Lauder  \n",
       "1  Estée Lauder  \n",
       "2  Estée Lauder  \n",
       "3  Estée Lauder  \n",
       "4  Estée Lauder  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df = pd.read_csv(output_path + \"subreddit_data.csv\")\n",
    "subreddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_brand_df = pd.read_csv(f\"../../../data/all_brands.csv\")\n",
    "all_brands = set(all_brand_df[\"brand_name\"].dropna().str.lower().unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Break each comment into a row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3196, 5)\n",
      "(1304, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "      <th>subreddit_name</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1bv7f30</td>\n",
       "      <td>[Product Question] Estée Lauder ANR - Allergic</td>\n",
       "      <td>Estée Lauder</td>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>Return it? Give it to someone?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1bv7f30</td>\n",
       "      <td>[Product Question] Estée Lauder ANR - Allergic</td>\n",
       "      <td>Estée Lauder</td>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>You can try to use it on your chest area to se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>psd79w</td>\n",
       "      <td>[Product Question] Estée Lauder Advanced Night...</td>\n",
       "      <td>Estée Lauder</td>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>I've used this serum for years and it's one of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>psd79w</td>\n",
       "      <td>[Product Question] Estée Lauder Advanced Night...</td>\n",
       "      <td>Estée Lauder</td>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>The more you use, the faster you use it up and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>psd79w</td>\n",
       "      <td>[Product Question] Estée Lauder Advanced Night...</td>\n",
       "      <td>Estée Lauder</td>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>Hi am I the only one who feel like my serum bo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                              title         brand  \\\n",
       "0  1bv7f30     [Product Question] Estée Lauder ANR - Allergic  Estée Lauder   \n",
       "1  1bv7f30     [Product Question] Estée Lauder ANR - Allergic  Estée Lauder   \n",
       "2   psd79w  [Product Question] Estée Lauder Advanced Night...  Estée Lauder   \n",
       "3   psd79w  [Product Question] Estée Lauder Advanced Night...  Estée Lauder   \n",
       "5   psd79w  [Product Question] Estée Lauder Advanced Night...  Estée Lauder   \n",
       "\n",
       "      subreddit_name                                            comment  \n",
       "0  SkincareAddiction                     Return it? Give it to someone?  \n",
       "1  SkincareAddiction  You can try to use it on your chest area to se...  \n",
       "2  SkincareAddiction  I've used this serum for years and it's one of...  \n",
       "3  SkincareAddiction  The more you use, the faster you use it up and...  \n",
       "5  SkincareAddiction  Hi am I the only one who feel like my serum bo...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df[\"top_comments\"] = subreddit_df[\"top_comments\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    ")\n",
    "def mentions_other_brand(comment, current_brand):\n",
    "    comment = str(comment).lower()\n",
    "    current_brand = str(current_brand).lower()\n",
    "    for brand in all_brands:\n",
    "        if brand != current_brand and brand in comment:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "rows = []\n",
    "for _, row in subreddit_df.iterrows():\n",
    "    for comment in row[\"top_comments\"]:\n",
    "        rows.append({\n",
    "            \"post_id\": row[\"post_id\"],\n",
    "            \"title\": row[\"title\"],\n",
    "            \"brand\": row[\"brand\"],\n",
    "            \"subreddit_name\": row[\"subreddit_name\"],\n",
    "            \"comment\": comment\n",
    "        })\n",
    "        \n",
    "comments_df = pd.DataFrame(rows)\n",
    "print(comments_df.shape)\n",
    "# filter out comments that mention other brands\n",
    "comments_df = comments_df[~comments_df[\"comment\"].apply(lambda x: mentions_other_brand(x, comments_df[\"brand\"]))]\n",
    "print(comments_df.shape)\n",
    "comments_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1304, 6)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_stopwords = [\n",
    "    # Brand names (removed from analysis)\n",
    "    'estee', 'lauder', 'tarte', 'fenty', 'glossier', 'cosrx', 'etude',\n",
    "    'sulwhasoo', 'laneige', 'innisfree', 'elf',\n",
    "\n",
    "    # Platform-related\n",
    "    'video', 'youtube', 'tiktok', 'instagram', 'reel', 'feed',\n",
    "    'post', 'stories', 'caption', 'social', 'media',\n",
    "\n",
    "    # Engagement / action words\n",
    "    'like', 'likes', 'comment', 'comments', 'share', 'save', 'follow', 'subscribe',\n",
    "    'tag', 'click', 'link', 'bio', 'visit', 'dm', 'available', 'check',\n",
    "\n",
    "    # Time / filler\n",
    "    'today', 'now', 'new', 'soon', 'launch', 'launching', 'stay', 'tune', 'coming', 'back',\n",
    "\n",
    "    # General beauty-related terms\n",
    "    'beauty', 'skin', 'skincare', 'routine', 'makeup', 'product', 'products',\n",
    "    'face', 'body', 'glow', 'look', 'formula', 'texture', 'result',\n",
    "\n",
    "    # Emoji / symbols\n",
    "    '✨', '🔥', '💧', '💫', '😍', '💖', '🌟', '💥', '🧴', '📦', '🛍️',\n",
    "\n",
    "    # Overused positive adjectives\n",
    "    'feel', 'love', 'use', 'try', 'amazing', 'favorite', 'best', 'perfect', 'must', 'obsessed',\n",
    "\n",
    "    # Promotional terms\n",
    "    'shop', 'buy', 'discount', 'deal', 'sale', 'off', 'gift', 'giveaway', 'free', 'offer',\n",
    "\n",
    "    # Conversation filler\n",
    "    'hey', 'hello', 'welcome', 'thank', 'you', 'everyone', 'guys', 'hi', 'omg', 'pls', 'yay', 'get', 'got', 'let', 'us',\n",
    "    \"follow\", \"like\", \"likes\", \"just\", \"really\", \"thanks\", \"omg\",\n",
    "    \"hi\", \"hey\", \"pls\", \"please\", \"gonna\", \"tbh\", \"honestly\",\n",
    "    \"lol\", \"lmao\", \"idk\", \"link\", \"click\", \"watch\", \"dm\", \"recommend\",\n",
    "]\n",
    "\n",
    "stopword_set = set(nltk_stopwords.words('english')).union(custom_stopwords)\n",
    "\n",
    "def preprocess_comment(comment):\n",
    "    if not isinstance(comment, str):\n",
    "        return \"\"\n",
    "    # lower case \n",
    "    comment= comment.lower()\n",
    "    comment = re.sub(r\"http\\S+|www\\S+|@\\w+|#\\w+|u/\\w+\", \"\", comment)\n",
    "    comment = re.sub(r\"[^a-z\\s]\", \" \",comment)\n",
    "    comment = re.sub(r\"\\s+\", \" \", comment).strip()\n",
    "    tokens = word_tokenize(comment)\n",
    "    \n",
    "    # remove stopwords \n",
    "    filtered_tokens = [t for t in tokens if t.isalpha() and t not in stopword_set and len(t) > 2] \n",
    "    return \" \".join(filtered_tokens)\n",
    "\n",
    "comments_df[\"cleaned_comment\"] = comments_df[\"comment\"].apply(preprocess_comment)\n",
    "\n",
    "comments_df.to_csv(output_path + \"subreddit_comment_data.csv\", index=False)\n",
    "comments_df.head()\n",
    "comments_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qss-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
