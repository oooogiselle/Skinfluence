{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comment text cleaning \n",
    "1. Break each comment down into as a individual row \n",
    "2. Preprocess each row\n",
    "3. Export cleaned comment data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import re\n",
    "import ast\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "output_path = \"../../../data/alignment_analysis/\"\n",
    "os.makedirs(output_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Subreddit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit_name</th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>top_comments</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>1bv7f30</td>\n",
       "      <td>[Product Question] Est√©e Lauder ANR - Allergic</td>\n",
       "      <td>Anyone have idea what could be best use of thi...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>['Return it? Give it to someone?', 'You can tr...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Est√©e Lauder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>psd79w</td>\n",
       "      <td>[Product Question] Est√©e Lauder Advanced Night...</td>\n",
       "      <td>So I have started my first bottle of this seru...</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>[\"I've used this serum for years and it's one ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Est√©e Lauder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>wly2yu</td>\n",
       "      <td>[Product Question] Est√©e Lauder night repair s...</td>\n",
       "      <td>I have a coupon for a free sample and I‚Äôm thin...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[\"I absolutely love it and I've used it for ye...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Est√©e Lauder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>lx8cl1</td>\n",
       "      <td>[product question] Est√©e Lauder ANR smell</td>\n",
       "      <td>I have a couple of sample bottles of Est√©e Lau...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>['A few *years* old?\\n\\nYeah, dump that.', 'Yo...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Est√©e Lauder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>1i5q8th</td>\n",
       "      <td>[Product question] Dupe for Est√©e Lauder Advan...</td>\n",
       "      <td>I got this half off at Ulta based on the esthe...</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>['Missha time revolution night repair ampoule'...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Est√©e Lauder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subreddit_name  post_id  \\\n",
       "0  SkincareAddiction  1bv7f30   \n",
       "1  SkincareAddiction   psd79w   \n",
       "2  SkincareAddiction   wly2yu   \n",
       "3  SkincareAddiction   lx8cl1   \n",
       "4  SkincareAddiction  1i5q8th   \n",
       "\n",
       "                                               title  \\\n",
       "0     [Product Question] Est√©e Lauder ANR - Allergic   \n",
       "1  [Product Question] Est√©e Lauder Advanced Night...   \n",
       "2  [Product Question] Est√©e Lauder night repair s...   \n",
       "3          [product question] Est√©e Lauder ANR smell   \n",
       "4  [Product question] Dupe for Est√©e Lauder Advan...   \n",
       "\n",
       "                                         description  score  num_comments  \\\n",
       "0  Anyone have idea what could be best use of thi...      3             4   \n",
       "1  So I have started my first bottle of this seru...      7            24   \n",
       "2  I have a coupon for a free sample and I‚Äôm thin...      3             4   \n",
       "3  I have a couple of sample bottles of Est√©e Lau...      4             5   \n",
       "4  I got this half off at Ulta based on the esthe...      8             7   \n",
       "\n",
       "                                        top_comments  upvote_ratio  \\\n",
       "0  ['Return it? Give it to someone?', 'You can tr...           1.0   \n",
       "1  [\"I've used this serum for years and it's one ...           1.0   \n",
       "2  [\"I absolutely love it and I've used it for ye...           1.0   \n",
       "3  ['A few *years* old?\\n\\nYeah, dump that.', 'Yo...           1.0   \n",
       "4  ['Missha time revolution night repair ampoule'...           1.0   \n",
       "\n",
       "          brand  \n",
       "0  Est√©e Lauder  \n",
       "1  Est√©e Lauder  \n",
       "2  Est√©e Lauder  \n",
       "3  Est√©e Lauder  \n",
       "4  Est√©e Lauder  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df = pd.read_csv(output_path + \"subreddit_data.csv\")\n",
    "subreddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_brand_df = pd.read_csv(f\"../../../data/all_brands.csv\")\n",
    "all_brands = set(all_brand_df[\"brand_name\"].dropna().str.lower().unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Break each comment into a row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3196, 5)\n",
      "(1304, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "      <th>subreddit_name</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1bv7f30</td>\n",
       "      <td>[Product Question] Est√©e Lauder ANR - Allergic</td>\n",
       "      <td>Est√©e Lauder</td>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>Return it? Give it to someone?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1bv7f30</td>\n",
       "      <td>[Product Question] Est√©e Lauder ANR - Allergic</td>\n",
       "      <td>Est√©e Lauder</td>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>You can try to use it on your chest area to se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>psd79w</td>\n",
       "      <td>[Product Question] Est√©e Lauder Advanced Night...</td>\n",
       "      <td>Est√©e Lauder</td>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>I've used this serum for years and it's one of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>psd79w</td>\n",
       "      <td>[Product Question] Est√©e Lauder Advanced Night...</td>\n",
       "      <td>Est√©e Lauder</td>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>The more you use, the faster you use it up and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>psd79w</td>\n",
       "      <td>[Product Question] Est√©e Lauder Advanced Night...</td>\n",
       "      <td>Est√©e Lauder</td>\n",
       "      <td>SkincareAddiction</td>\n",
       "      <td>Hi am I the only one who feel like my serum bo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                              title         brand  \\\n",
       "0  1bv7f30     [Product Question] Est√©e Lauder ANR - Allergic  Est√©e Lauder   \n",
       "1  1bv7f30     [Product Question] Est√©e Lauder ANR - Allergic  Est√©e Lauder   \n",
       "2   psd79w  [Product Question] Est√©e Lauder Advanced Night...  Est√©e Lauder   \n",
       "3   psd79w  [Product Question] Est√©e Lauder Advanced Night...  Est√©e Lauder   \n",
       "5   psd79w  [Product Question] Est√©e Lauder Advanced Night...  Est√©e Lauder   \n",
       "\n",
       "      subreddit_name                                            comment  \n",
       "0  SkincareAddiction                     Return it? Give it to someone?  \n",
       "1  SkincareAddiction  You can try to use it on your chest area to se...  \n",
       "2  SkincareAddiction  I've used this serum for years and it's one of...  \n",
       "3  SkincareAddiction  The more you use, the faster you use it up and...  \n",
       "5  SkincareAddiction  Hi am I the only one who feel like my serum bo...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df[\"top_comments\"] = subreddit_df[\"top_comments\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    ")\n",
    "def mentions_other_brand(comment, current_brand):\n",
    "    comment = str(comment).lower()\n",
    "    current_brand = str(current_brand).lower()\n",
    "    for brand in all_brands:\n",
    "        if brand != current_brand and brand in comment:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "rows = []\n",
    "for _, row in subreddit_df.iterrows():\n",
    "    for comment in row[\"top_comments\"]:\n",
    "        rows.append({\n",
    "            \"post_id\": row[\"post_id\"],\n",
    "            \"title\": row[\"title\"],\n",
    "            \"brand\": row[\"brand\"],\n",
    "            \"subreddit_name\": row[\"subreddit_name\"],\n",
    "            \"comment\": comment\n",
    "        })\n",
    "        \n",
    "comments_df = pd.DataFrame(rows)\n",
    "print(comments_df.shape)\n",
    "# filter out comments that mention other brands\n",
    "comments_df = comments_df[~comments_df[\"comment\"].apply(lambda x: mentions_other_brand(x, comments_df[\"brand\"]))]\n",
    "print(comments_df.shape)\n",
    "comments_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1304, 6)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_stopwords = [\n",
    "    # Brand names (removed from analysis)\n",
    "    'estee', 'lauder', 'tarte', 'fenty', 'glossier', 'cosrx', 'etude',\n",
    "    'sulwhasoo', 'laneige', 'innisfree', 'elf',\n",
    "\n",
    "    # Platform-related\n",
    "    'video', 'youtube', 'tiktok', 'instagram', 'reel', 'feed',\n",
    "    'post', 'stories', 'caption', 'social', 'media',\n",
    "\n",
    "    # Engagement / action words\n",
    "    'like', 'likes', 'comment', 'comments', 'share', 'save', 'follow', 'subscribe',\n",
    "    'tag', 'click', 'link', 'bio', 'visit', 'dm', 'available', 'check',\n",
    "\n",
    "    # Time / filler\n",
    "    'today', 'now', 'new', 'soon', 'launch', 'launching', 'stay', 'tune', 'coming', 'back',\n",
    "\n",
    "    # General beauty-related terms\n",
    "    'beauty', 'skin', 'skincare', 'routine', 'makeup', 'product', 'products',\n",
    "    'face', 'body', 'glow', 'look', 'formula', 'texture', 'result',\n",
    "\n",
    "    # Emoji / symbols\n",
    "    '‚ú®', 'üî•', 'üíß', 'üí´', 'üòç', 'üíñ', 'üåü', 'üí•', 'üß¥', 'üì¶', 'üõçÔ∏è',\n",
    "\n",
    "    # Overused positive adjectives\n",
    "    'feel', 'love', 'use', 'try', 'amazing', 'favorite', 'best', 'perfect', 'must', 'obsessed',\n",
    "\n",
    "    # Promotional terms\n",
    "    'shop', 'buy', 'discount', 'deal', 'sale', 'off', 'gift', 'giveaway', 'free', 'offer',\n",
    "\n",
    "    # Conversation filler\n",
    "    'hey', 'hello', 'welcome', 'thank', 'you', 'everyone', 'guys', 'hi', 'omg', 'pls', 'yay', 'get', 'got', 'let', 'us',\n",
    "    \"follow\", \"like\", \"likes\", \"just\", \"really\", \"thanks\", \"omg\",\n",
    "    \"hi\", \"hey\", \"pls\", \"please\", \"gonna\", \"tbh\", \"honestly\",\n",
    "    \"lol\", \"lmao\", \"idk\", \"link\", \"click\", \"watch\", \"dm\", \"recommend\",\n",
    "]\n",
    "\n",
    "stopword_set = set(nltk_stopwords.words('english')).union(custom_stopwords)\n",
    "\n",
    "def preprocess_comment(comment):\n",
    "    if not isinstance(comment, str):\n",
    "        return \"\"\n",
    "    # lower case \n",
    "    comment= comment.lower()\n",
    "    comment = re.sub(r\"http\\S+|www\\S+|@\\w+|#\\w+|u/\\w+\", \"\", comment)\n",
    "    comment = re.sub(r\"[^a-z\\s]\", \" \",comment)\n",
    "    comment = re.sub(r\"\\s+\", \" \", comment).strip()\n",
    "    tokens = word_tokenize(comment)\n",
    "    \n",
    "    # remove stopwords \n",
    "    filtered_tokens = [t for t in tokens if t.isalpha() and t not in stopword_set and len(t) > 2] \n",
    "    return \" \".join(filtered_tokens)\n",
    "\n",
    "comments_df[\"cleaned_comment\"] = comments_df[\"comment\"].apply(preprocess_comment)\n",
    "\n",
    "comments_df.to_csv(output_path + \"subreddit_comment_data.csv\", index=False)\n",
    "comments_df.head()\n",
    "comments_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qss-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
