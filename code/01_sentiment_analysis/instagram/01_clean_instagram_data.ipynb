{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "## nltk imports\n",
    "#!pip install nltk # can install on terminal or by uncommenting this line\n",
    "#import nltk; nltk.download('punkt'); nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all instagram data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../../data/instagram'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "estee_df = pd.read_csv(f\"{data_path}/estee_lauder.csv\")\n",
    "tarte_df = pd.read_csv(f\"{data_path}/tarte_cosmetics.csv\")\n",
    "innisfree_df = pd.read_csv(f\"{data_path}/innisfree.csv\")\n",
    "elf_df = pd.read_csv(f\"{data_path}/elf_cosmetics.csv\")\n",
    "glossier_df = pd.read_csv(f\"{data_path}/glossier.csv\",\n",
    "    low_memory=False)\n",
    "laneige_df = pd.read_csv(f\"{data_path}/laneige.csv\")\n",
    "sulwhasoo_df = pd.read_csv(f\"{data_path}/sulwhasoo.csv\")\n",
    "etude_df = pd.read_csv(f\"{data_path}/etude_house.csv\")\n",
    "cosrx_df = pd.read_csv(f\"{data_path}/cosrx.csv\",low_memory=False)\n",
    "fenty_df = pd.read_csv(f\"{data_path}/fenty_beauty.csv\",low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "estee_df[\"brand\"] = \"EstÃ©e Lauder\"\n",
    "tarte_df[\"brand\"] = \"Tarte\"\n",
    "innisfree_df[\"brand\"] = \"Innisfree\"\n",
    "elf_df[\"brand\"] = \"e.l.f\"\n",
    "glossier_df[\"brand\"] = \"Glossier\"\n",
    "laneige_df[\"brand\"] = \"Laneige\"\n",
    "sulwhasoo_df[\"brand\"] = \"Sulwhasoo\"\n",
    "etude_df[\"brand\"] = \"Etude\"\n",
    "cosrx_df[\"brand\"] = \"COSRX\"\n",
    "fenty_df[\"brand\"] = \"Fenty Beauty\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat everything\n",
    "\n",
    "all_df = pd.concat([\n",
    "    estee_df, tarte_df, innisfree_df, elf_df, glossier_df,\n",
    "    laneige_df, sulwhasoo_df, etude_df, cosrx_df, fenty_df\n",
    "], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.sample(20)\n",
    "all_df.to_csv(f\"{data_path}/raw_instagram_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Instagram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_words_toad = [\n",
    "    # Brand names (removed from analysis)\n",
    "    'estee', 'lauder', 'tarte', 'fenty', 'glossier', 'cosrx', 'etude',\n",
    "    'sulwhasoo', 'laneige', 'innisfree', 'elf',\n",
    "\n",
    "    # Platform-related\n",
    "    'video', 'youtube', 'tiktok', 'instagram', 'reel', 'feed',\n",
    "    'post', 'stories', 'caption', 'social', 'media',\n",
    "\n",
    "    # Engagement / action words\n",
    "    'like', 'likes', 'comment', 'comments', 'share', 'save', 'follow', 'subscribe',\n",
    "    'tag', 'click', 'link', 'bio', 'visit', 'dm', 'available', 'check',\n",
    "\n",
    "    # Time / filler\n",
    "    'today', 'now', 'new', 'soon', 'launch', 'launching', 'stay', 'tune', 'coming', 'back',\n",
    "\n",
    "    # General beauty-related terms\n",
    "    'beauty', 'skin', 'skincare', 'routine', 'makeup', 'product', 'products',\n",
    "    'face', 'body', 'glow', 'look', 'formula', 'texture', 'result',\n",
    "\n",
    "    # Emoji / symbols\n",
    "    'âœ¨', 'ðŸ”¥', 'ðŸ’§', 'ðŸ’«', 'ðŸ˜', 'ðŸ’–', 'ðŸŒŸ', 'ðŸ’¥', 'ðŸ§´', 'ðŸ“¦', 'ðŸ›ï¸',\n",
    "\n",
    "    # Overused positive adjectives\n",
    "    'feel', 'love', 'use', 'try', 'amazing', 'favorite', 'best', 'perfect', 'must', 'obsessed',\n",
    "\n",
    "    # Promotional terms\n",
    "    'shop', 'buy', 'discount', 'deal', 'sale', 'off', 'gift', 'giveaway', 'free', 'offer',\n",
    "\n",
    "    # Conversation filler\n",
    "    'hey', 'hello', 'welcome', 'thank', 'you', 'everyone', 'guys', 'hi', 'omg', 'pls', 'yay', 'get', 'got', 'let', 'us'\n",
    "]\n",
    "\n",
    "\n",
    "def preprocess(df_col, custom_words_toad):\n",
    "    porter = PorterStemmer()\n",
    "    list_stopwords = stopwords.words(\"english\")\n",
    "    new_stopwords = set(list_stopwords + custom_words_toad)\n",
    "\n",
    "    corpus_lower = df_col.fillna(\"\").str.lower().to_list()\n",
    "\n",
    "    nostop_listing = []\n",
    "    for text in corpus_lower:\n",
    "        # Clean URLs\n",
    "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "        text = re.sub(r\"[^\\w\\s]\", '', text)\n",
    "        # Tokenize and remove stopwords\n",
    "        tokens = [\n",
    "            word for word in wordpunct_tokenize(text)\n",
    "            if word.isalpha() and word not in new_stopwords\n",
    "        ]\n",
    "        # Apply stemming\n",
    "        stemmed_tokens = [porter.stem(word) for word in tokens if len(word) > 2]\n",
    "        nostop_listing.append(stemmed_tokens)\n",
    "\n",
    "    return nostop_listing\n",
    "    \n",
    "# already ran this before\n",
    "all_df[\"text_clean\"] = preprocess(all_df[\"text\"], custom_words_toad)\n",
    "all_df[\"text_clean_str\"] = all_df[\"text_clean\"].apply(lambda tokens: \" \".join(tokens).lower() if isinstance(tokens, (list, tuple)) else \"\")\n",
    "all_df.to_csv(f\"{data_path}/all_instagram_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216850, 22)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qss-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
