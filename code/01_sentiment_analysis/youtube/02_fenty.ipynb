{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80072b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "## lda\n",
    "# !pip install gensim # can install by uncommenting this line\n",
    "from gensim import corpora\n",
    "import gensim\n",
    "## visualizing LDA--likely need to install\n",
    "# !pip install pyLDAvis # can install by uncommenting this line\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "pyLDAvis.enable_notebook()\n",
    "## specify to print all output in a call\n",
    "## and not just first\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48bbf3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "data_path = \"../../../data/youtube/\"\n",
    "output_path = \"../../../output/sentiment_analysis/youtube/fenty/\"\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bb77b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/qss-nlp/lib/python3.11/site-packages/spacy/cli/_util.py:23: DeprecationWarning: Importing 'parser.split_arg_string' is deprecated, it will only be available in 'shell_completion' in Click 9.0.\n",
      "  from click.parser import split_arg_string\n",
      "/opt/miniconda3/envs/qss-nlp/lib/python3.11/site-packages/weasel/util/config.py:8: DeprecationWarning: Importing 'parser.split_arg_string' is deprecated, it will only be available in 'shell_completion' in Click 9.0.\n",
      "  from click.parser import split_arg_string\n"
     ]
    }
   ],
   "source": [
    "## spacy --- if you get an error at the load step\n",
    "## need to download en_core_web_sm (google or try the next line)\n",
    "#!python -m spacy download en_core_web_sm\n",
    "import spacy\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9938e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>channel</th>\n",
       "      <th>published</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GY90IvsNbvw</td>\n",
       "      <td>TOP 5 FENTY BEAUTY PRODUCTS</td>\n",
       "      <td>MENTIONED Gloss Bomb https://go.magik.ly/ml/1r...</td>\n",
       "      <td>Morgan Turner</td>\n",
       "      <td>2023-02-14T22:00:07Z</td>\n",
       "      <td>254400</td>\n",
       "      <td>17591.0</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A50_AmSTdVE</td>\n",
       "      <td>Rihanna‚Äôs before &amp;amp; after using THIS founda...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fenty Beauty By Rihanna</td>\n",
       "      <td>2024-08-07T21:49:02Z</td>\n",
       "      <td>4308333</td>\n",
       "      <td>216894.0</td>\n",
       "      <td>1990.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4LwpGaDKmZ8</td>\n",
       "      <td>FENTY BEAUTY by RIHANNA... Is It Jeffree Star ...</td>\n",
       "      <td>HEY EVERYONE! Today I'm doing a review and fir...</td>\n",
       "      <td>jeffreestar</td>\n",
       "      <td>2017-09-08T21:50:21Z</td>\n",
       "      <td>13370589</td>\n",
       "      <td>322285.0</td>\n",
       "      <td>19902.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N_zDcuX1Y54</td>\n",
       "      <td>RIHANNA: FENTY BEAUTY - Review + First Impress...</td>\n",
       "      <td>Make sure you subscribe to my channel and hit ...</td>\n",
       "      <td>NikkieTutorials</td>\n",
       "      <td>2017-09-19T20:33:57Z</td>\n",
       "      <td>10381946</td>\n",
       "      <td>252956.0</td>\n",
       "      <td>10111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bH7M3vBcdcw</td>\n",
       "      <td>FENTY BEAUTY BY RIHANNA | FULL FACE + REVIEW |...</td>\n",
       "      <td>I've been dying to get my hands on the NEW Fen...</td>\n",
       "      <td>Jasmine Brown</td>\n",
       "      <td>2017-09-10T16:12:13Z</td>\n",
       "      <td>668028</td>\n",
       "      <td>24543.0</td>\n",
       "      <td>705.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                              title  \\\n",
       "0  GY90IvsNbvw                        TOP 5 FENTY BEAUTY PRODUCTS   \n",
       "1  A50_AmSTdVE  Rihanna‚Äôs before &amp; after using THIS founda...   \n",
       "2  4LwpGaDKmZ8  FENTY BEAUTY by RIHANNA... Is It Jeffree Star ...   \n",
       "3  N_zDcuX1Y54  RIHANNA: FENTY BEAUTY - Review + First Impress...   \n",
       "4  bH7M3vBcdcw  FENTY BEAUTY BY RIHANNA | FULL FACE + REVIEW |...   \n",
       "\n",
       "                                         description                  channel  \\\n",
       "0  MENTIONED Gloss Bomb https://go.magik.ly/ml/1r...            Morgan Turner   \n",
       "1                                                NaN  Fenty Beauty By Rihanna   \n",
       "2  HEY EVERYONE! Today I'm doing a review and fir...              jeffreestar   \n",
       "3  Make sure you subscribe to my channel and hit ...          NikkieTutorials   \n",
       "4  I've been dying to get my hands on the NEW Fen...            Jasmine Brown   \n",
       "\n",
       "              published     views     likes  comments  \n",
       "0  2023-02-14T22:00:07Z    254400   17591.0      87.0  \n",
       "1  2024-08-07T21:49:02Z   4308333  216894.0    1990.0  \n",
       "2  2017-09-08T21:50:21Z  13370589  322285.0   19902.0  \n",
       "3  2017-09-19T20:33:57Z  10381946  252956.0   10111.0  \n",
       "4  2017-09-10T16:12:13Z    668028   24543.0     705.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fenty_df = pd.read_csv(data_path + \"youtube_fenty.csv\")\n",
    "fenty_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d54352a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## clean data first\n",
    "def clean_text(text):\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove URLs and links\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove punctuation (optional if you want cleaner tokens)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Remove numbers (optional)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove extra spaces and lowercase\n",
    "    text = text.lower().strip()\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "326193d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fenty_df['text_clean'] = (fenty_df['title'].fillna('') + ' ' + fenty_df['description'].fillna('')).apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89df0802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>channel</th>\n",
       "      <th>published</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GY90IvsNbvw</td>\n",
       "      <td>TOP 5 FENTY BEAUTY PRODUCTS</td>\n",
       "      <td>MENTIONED Gloss Bomb https://go.magik.ly/ml/1r...</td>\n",
       "      <td>Morgan Turner</td>\n",
       "      <td>2023-02-14T22:00:07Z</td>\n",
       "      <td>254400</td>\n",
       "      <td>17591.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>top  fenty beauty products mentioned gloss bom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A50_AmSTdVE</td>\n",
       "      <td>Rihanna‚Äôs before &amp;amp; after using THIS founda...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fenty Beauty By Rihanna</td>\n",
       "      <td>2024-08-07T21:49:02Z</td>\n",
       "      <td>4308333</td>\n",
       "      <td>216894.0</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>rihannas before amp after using this foundatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4LwpGaDKmZ8</td>\n",
       "      <td>FENTY BEAUTY by RIHANNA... Is It Jeffree Star ...</td>\n",
       "      <td>HEY EVERYONE! Today I'm doing a review and fir...</td>\n",
       "      <td>jeffreestar</td>\n",
       "      <td>2017-09-08T21:50:21Z</td>\n",
       "      <td>13370589</td>\n",
       "      <td>322285.0</td>\n",
       "      <td>19902.0</td>\n",
       "      <td>fenty beauty by rihanna is it jeffree star app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N_zDcuX1Y54</td>\n",
       "      <td>RIHANNA: FENTY BEAUTY - Review + First Impress...</td>\n",
       "      <td>Make sure you subscribe to my channel and hit ...</td>\n",
       "      <td>NikkieTutorials</td>\n",
       "      <td>2017-09-19T20:33:57Z</td>\n",
       "      <td>10381946</td>\n",
       "      <td>252956.0</td>\n",
       "      <td>10111.0</td>\n",
       "      <td>rihanna fenty beauty  review  first impression...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bH7M3vBcdcw</td>\n",
       "      <td>FENTY BEAUTY BY RIHANNA | FULL FACE + REVIEW |...</td>\n",
       "      <td>I've been dying to get my hands on the NEW Fen...</td>\n",
       "      <td>Jasmine Brown</td>\n",
       "      <td>2017-09-10T16:12:13Z</td>\n",
       "      <td>668028</td>\n",
       "      <td>24543.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>fenty beauty by rihanna  full face  review  ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3813</th>\n",
       "      <td>XWrB4qOF_UA</td>\n",
       "      <td>FENTY BEAUTY BODY LAVA &amp;amp; FAIRY BOMB | HIT ...</td>\n",
       "      <td>HEY EVERYONE! Where are all my glow addicts at...</td>\n",
       "      <td>jeffreestar</td>\n",
       "      <td>2018-04-08T17:15:51Z</td>\n",
       "      <td>4871365</td>\n",
       "      <td>154354.0</td>\n",
       "      <td>10915.0</td>\n",
       "      <td>fenty beauty body lava amp fairy bomb  hit or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3814</th>\n",
       "      <td>vxicEG2iYUE</td>\n",
       "      <td>FENTY BEAUTY IN INDIA #fentybeauty #glossylips...</td>\n",
       "      <td>FENTY BEAUTY NOW IN INDIA @mynykaa Cross Borde...</td>\n",
       "      <td>Zohainsight</td>\n",
       "      <td>2024-03-12T19:06:39Z</td>\n",
       "      <td>13375</td>\n",
       "      <td>244.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>fenty beauty in india fentybeauty glossylips l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3815</th>\n",
       "      <td>YtUxmVmsJJA</td>\n",
       "      <td>FENTY PRO FILT&amp;#39;R CONCEALER VS TARTE SHAPE ...</td>\n",
       "      <td>Hola my babes! Hope you're all doing great tod...</td>\n",
       "      <td>Dilan Sabah</td>\n",
       "      <td>2019-01-14T19:04:08Z</td>\n",
       "      <td>80635</td>\n",
       "      <td>1168.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>fenty pro filtr concealer vs tarte shape tape ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3816</th>\n",
       "      <td>bcZNf6U5fIg</td>\n",
       "      <td>FENTY BEAUTY LIPSTICK DUPE- ‚Çπ2500 vs ‚Çπ599üò± | #...</td>\n",
       "      <td>Part III- FAV LIPSTICK DUPES!! #episode3 I lov...</td>\n",
       "      <td>Disha Batra</td>\n",
       "      <td>2021-09-09T13:58:21Z</td>\n",
       "      <td>24591</td>\n",
       "      <td>754.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>fenty beauty lipstick dupe  vs   shorts dupes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3817</th>\n",
       "      <td>HQ3rBL1oaS4</td>\n",
       "      <td>Cecred vs Fenty Hair Final Review ... Plus My ...</td>\n",
       "      <td>In this.video, I discuss my final thoughts on ...</td>\n",
       "      <td>Trish the Natural</td>\n",
       "      <td>2024-08-08T00:00:07Z</td>\n",
       "      <td>1204</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>cecred vs fenty hair final review  plus my tho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3818 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id                                              title  \\\n",
       "0     GY90IvsNbvw                        TOP 5 FENTY BEAUTY PRODUCTS   \n",
       "1     A50_AmSTdVE  Rihanna‚Äôs before &amp; after using THIS founda...   \n",
       "2     4LwpGaDKmZ8  FENTY BEAUTY by RIHANNA... Is It Jeffree Star ...   \n",
       "3     N_zDcuX1Y54  RIHANNA: FENTY BEAUTY - Review + First Impress...   \n",
       "4     bH7M3vBcdcw  FENTY BEAUTY BY RIHANNA | FULL FACE + REVIEW |...   \n",
       "...           ...                                                ...   \n",
       "3813  XWrB4qOF_UA  FENTY BEAUTY BODY LAVA &amp; FAIRY BOMB | HIT ...   \n",
       "3814  vxicEG2iYUE  FENTY BEAUTY IN INDIA #fentybeauty #glossylips...   \n",
       "3815  YtUxmVmsJJA  FENTY PRO FILT&#39;R CONCEALER VS TARTE SHAPE ...   \n",
       "3816  bcZNf6U5fIg  FENTY BEAUTY LIPSTICK DUPE- ‚Çπ2500 vs ‚Çπ599üò± | #...   \n",
       "3817  HQ3rBL1oaS4  Cecred vs Fenty Hair Final Review ... Plus My ...   \n",
       "\n",
       "                                            description  \\\n",
       "0     MENTIONED Gloss Bomb https://go.magik.ly/ml/1r...   \n",
       "1                                                   NaN   \n",
       "2     HEY EVERYONE! Today I'm doing a review and fir...   \n",
       "3     Make sure you subscribe to my channel and hit ...   \n",
       "4     I've been dying to get my hands on the NEW Fen...   \n",
       "...                                                 ...   \n",
       "3813  HEY EVERYONE! Where are all my glow addicts at...   \n",
       "3814  FENTY BEAUTY NOW IN INDIA @mynykaa Cross Borde...   \n",
       "3815  Hola my babes! Hope you're all doing great tod...   \n",
       "3816  Part III- FAV LIPSTICK DUPES!! #episode3 I lov...   \n",
       "3817  In this.video, I discuss my final thoughts on ...   \n",
       "\n",
       "                      channel             published     views     likes  \\\n",
       "0               Morgan Turner  2023-02-14T22:00:07Z    254400   17591.0   \n",
       "1     Fenty Beauty By Rihanna  2024-08-07T21:49:02Z   4308333  216894.0   \n",
       "2                 jeffreestar  2017-09-08T21:50:21Z  13370589  322285.0   \n",
       "3             NikkieTutorials  2017-09-19T20:33:57Z  10381946  252956.0   \n",
       "4               Jasmine Brown  2017-09-10T16:12:13Z    668028   24543.0   \n",
       "...                       ...                   ...       ...       ...   \n",
       "3813              jeffreestar  2018-04-08T17:15:51Z   4871365  154354.0   \n",
       "3814              Zohainsight  2024-03-12T19:06:39Z     13375     244.0   \n",
       "3815              Dilan Sabah  2019-01-14T19:04:08Z     80635    1168.0   \n",
       "3816              Disha Batra  2021-09-09T13:58:21Z     24591     754.0   \n",
       "3817        Trish the Natural  2024-08-08T00:00:07Z      1204      30.0   \n",
       "\n",
       "      comments                                         text_clean  \n",
       "0         87.0  top  fenty beauty products mentioned gloss bom...  \n",
       "1       1990.0  rihannas before amp after using this foundatio...  \n",
       "2      19902.0  fenty beauty by rihanna is it jeffree star app...  \n",
       "3      10111.0  rihanna fenty beauty  review  first impression...  \n",
       "4        705.0  fenty beauty by rihanna  full face  review  ja...  \n",
       "...        ...                                                ...  \n",
       "3813   10915.0  fenty beauty body lava amp fairy bomb  hit or ...  \n",
       "3814       3.0  fenty beauty in india fentybeauty glossylips l...  \n",
       "3815      96.0  fenty pro filtr concealer vs tarte shape tape ...  \n",
       "3816       6.0  fenty beauty lipstick dupe  vs   shorts dupes ...  \n",
       "3817      30.0  cecred vs fenty hair final review  plus my tho...  \n",
       "\n",
       "[3818 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fenty_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddd2aee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tokenize\n",
    "tokens_pos_list = []\n",
    "for description in fenty_df['text_clean'].dropna():\n",
    "    description = str(description)\n",
    "    tokens = word_tokenize(description)\n",
    "    tokens_pos = pos_tag(tokens)\n",
    "    tokens_pos_list.append(tokens_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ee57c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stem\n",
    "custom_words_toad = ['fenty', 'rihanna', 'video', 'fentybeauty','youtube', 'youtuber', 'likes', 'comments', 'today', 'hey','subcribe','makeup','skincare','skin','beauty','new','product']\n",
    "\n",
    "def preprocess(df_col, custom_words_toad):\n",
    "    porter = PorterStemmer()\n",
    "    list_stopwords = stopwords.words(\"english\")\n",
    "    new_stopwords = set(list_stopwords + custom_words_toad)\n",
    "\n",
    "    corpus_lower = df_col.fillna(\"\").str.lower().to_list()\n",
    "\n",
    "    nostop_listing = []\n",
    "    for text in corpus_lower:\n",
    "        # Clean URLs\n",
    "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "        # Tokenize and remove stopwords\n",
    "        tokens = [\n",
    "            word for word in wordpunct_tokenize(text)\n",
    "            if word.isalpha() and word not in new_stopwords\n",
    "        ]\n",
    "        # Apply stemming\n",
    "        stemmed_tokens = [porter.stem(word) for word in tokens if len(word) > 2]\n",
    "        nostop_listing.append(stemmed_tokens)\n",
    "\n",
    "    return nostop_listing\n",
    "    \n",
    "fenty_df['cleaned_description'] = preprocess(fenty_df['description'], custom_words_toad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "be82edc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## function provided\n",
    "def create_dtm(list_of_strings, metadata):\n",
    "    \"\"\" \n",
    "    Function to create dense document-term matrix (DTM) from a list of strings and provided metadata. \n",
    "    A sparse DTM is a list of term_index/doc_index tuples: if a given term occurs in a given doc at least once, \n",
    "        then this count is listed as a tuple; if not, that term/doc pair is omitted. \n",
    "    In a dense DTM, each row is one text (e.g., an Airbnb listing), each column is a term, and \n",
    "        each cell indicates the frequency of that word in that text. \n",
    "    \n",
    "    Parameters:\n",
    "        list_of_strings (Series): each row contains a preprocessed string (need not be tokenized)\n",
    "        metadata (DataFrame): contains document-level covariates\n",
    "    \n",
    "    Returns:\n",
    "        Dense DTM with metadata on left and then one column per word in lexicon\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize a sklearn tokenizer; this helps us tokenize the preprocessed string input\n",
    "    vectorizer = CountVectorizer(lowercase = True) \n",
    "    dtm_sparse = vectorizer.fit_transform(list_of_strings)\n",
    "    print('Sparse matrix form:\\n', dtm_sparse[:3]) # take a look at sparse representation\n",
    "    print()\n",
    "    \n",
    "    # switch the dataframe from the sparse representation to the normal dense representation (so we can treat it as regular dataframe)\n",
    "    dtm_dense_named = pd.DataFrame(dtm_sparse.todense(), columns=vectorizer.get_feature_names_out ())\n",
    "    print('Dense matrix form:\\n', dtm_dense_named.head()) # take a look at dense representation\n",
    "    dtm_dense_named_withid = pd.concat([metadata.reset_index(), dtm_dense_named], axis = 1) # add back document-level covariates\n",
    "\n",
    "    return(dtm_dense_named_withid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e81bb538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse matrix form:\n",
      "   (0, 2255)\t1\n",
      "  (0, 1466)\t1\n",
      "  (0, 390)\t1\n",
      "  (0, 433)\t1\n",
      "  (0, 1309)\t1\n",
      "  (0, 714)\t1\n",
      "  (0, 1016)\t1\n",
      "  (0, 985)\t1\n",
      "  (0, 3611)\t1\n",
      "  (2, 1135)\t1\n",
      "  (2, 2950)\t1\n",
      "  (2, 1306)\t1\n",
      "  (2, 1742)\t1\n",
      "  (2, 2041)\t1\n",
      "  (2, 1975)\t1\n",
      "  (2, 2449)\t1\n",
      "  (2, 1500)\t1\n",
      "\n",
      "Dense matrix form:\n",
      "    abeg  aber  abh  abl  abloh  abod  abonn  abonnez  aborigin  aboutbest  \\\n",
      "0     0     0    0    0      0     0      0        0         0          0   \n",
      "1     0     0    0    0      0     0      0        0         0          0   \n",
      "2     0     0    0    0      0     0      0        0         0          0   \n",
      "3     0     0    0    0      0     0      0        0         0          0   \n",
      "4     0     0    0    0      0     0      0        0         0          0   \n",
      "\n",
      "   ...  Áªßladi  ËïæÂìàÂ®úÂíåÂä≥‰º¶  Í∏ÄÎ°úÎ≤å  Î∑∞Ìã∞Í±∏Îì§Í≥º  Î∑∞Ìã∞ÌîåÎ†àÏù¥  ÏÑúÌè¨ÌÑ∞Ï¶àÏûÖÎãàÎã§  ÏãúÏûëÌï©ÎãàÎã§  ÏòÅÏÉÅÏóê  Ïù∏ÌÑ∞Î∑∞Ïù¥Îäî  Ï∂úÏó∞Ìïú  \n",
      "0  ...      0       0    0      0      0        0      0    0      0    0  \n",
      "1  ...      0       0    0      0      0        0      0    0      0    0  \n",
      "2  ...      0       0    0      0      0        0      0    0      0    0  \n",
      "3  ...      0       0    0      0      0        0      0    0      0    0  \n",
      "4  ...      0       0    0      0      0        0      0    0      0    0  \n",
      "\n",
      "[5 rows x 4033 columns]\n"
     ]
    }
   ],
   "source": [
    "string_docs = fenty_df.cleaned_description.apply(lambda tokens: ' '.join(tokens))\n",
    "dtm_nopre = create_dtm(\n",
    "    list_of_strings=string_docs,\n",
    "    metadata=fenty_df[['video_id', 'channel', 'views', 'likes', 'comments']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a283af90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review      349\n",
      "foundat     296\n",
      "product     262\n",
      "subscrib    198\n",
      "lip         192\n",
      "use         185\n",
      "guy         183\n",
      "welcom      176\n",
      "watch       173\n",
      "tri         173\n",
      "love        161\n",
      "hope        155\n",
      "pro         155\n",
      "first       155\n",
      "get         154\n",
      "short       151\n",
      "back        148\n",
      "gloss       143\n",
      "shade       140\n",
      "full        137\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Skip metadata columns manually\n",
    "term_columns = dtm_nopre.columns.difference(['video_id', 'channel', 'views', 'likes', 'comments', 'index'])\n",
    "top_terms = dtm_nopre[term_columns].sum(axis=0)\n",
    "top_terms_sorted = top_terms.sort_values(ascending=False)\n",
    "\n",
    "print(top_terms_sorted.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a4e93cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'bomb', 1: 'bright', 2: 'conceal', 3: 'drop', 4: 'eaz'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering out very rare and very common words reduced the length of dictionary from 4033 to 3.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'review', 1: 'foundat', 2: 'product'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of documents represented in dictionary format (with omitted words noted):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[([],\n",
       "  {'bomb': 1,\n",
       "   'bright': 1,\n",
       "   'conceal': 1,\n",
       "   'drop': 1,\n",
       "   'eaz': 1,\n",
       "   'fix': 1,\n",
       "   'gloss': 1,\n",
       "   'mention': 1,\n",
       "   'tint': 1}),\n",
       " ([], {}),\n",
       " ([(0, 1)],\n",
       "  {'everyon': 1,\n",
       "   'first': 1,\n",
       "   'got': 1,\n",
       "   'impress': 1,\n",
       "   'last': 1,\n",
       "   'line': 1,\n",
       "   'night': 1}),\n",
       " ([],\n",
       "  {'bell': 1,\n",
       "   'channel': 1,\n",
       "   'hit': 1,\n",
       "   'make': 1,\n",
       "   'miss': 1,\n",
       "   'notif': 1,\n",
       "   'subscrib': 1,\n",
       "   'sure': 1,\n",
       "   'video': 1}),\n",
       " ([(0, 1)],\n",
       "  {'die': 1,\n",
       "   'first': 1,\n",
       "   'get': 1,\n",
       "   'hand': 1,\n",
       "   'impress': 1,\n",
       "   'line': 1,\n",
       "   'want': 1}),\n",
       " ([],\n",
       "  {'absolut': 1,\n",
       "   'everyon': 1,\n",
       "   'face': 1,\n",
       "   'forget': 1,\n",
       "   'full': 1,\n",
       "   'let': 1,\n",
       "   'look': 1,\n",
       "   'love': 1,\n",
       "   'much': 1,\n",
       "   'thank': 1,\n",
       "   'watch': 1}),\n",
       " ([],\n",
       "  {'diffus': 1,\n",
       "   'filt': 1,\n",
       "   'instant': 1,\n",
       "   'pore': 1,\n",
       "   'primer': 3,\n",
       "   'pro': 1,\n",
       "   'rare': 1,\n",
       "   'retouch': 1}),\n",
       " ([], {'channel': 1, 'launch': 1, 'sister': 1, 'subscrib': 1, 'video': 1}),\n",
       " ([], {'bomb': 1, 'fok': 1, 'gloss': 1, 'must': 1, 'stix': 1}),\n",
       " ([], {'code': 1, 'fat': 1, 'get': 1, 'use': 1, 'water': 1})]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## Step 1: re-tokenize and store in list\n",
    "## here, i'm doing with the raw random sample of text\n",
    "## in activity, you should do with the preprocessed texts\n",
    "text_raw_tokens = fenty_df.cleaned_description\n",
    "\n",
    "\n",
    "\n",
    "## Step 2: use gensim create dictionary - gets all unique words across documents\n",
    "text_raw_dict = corpora.Dictionary(text_raw_tokens)\n",
    "raw_len = len(text_raw_dict) # get length for comparison below\n",
    "\n",
    "### explore first few keys and values\n",
    "### see that key is just an arbitrary counter; value is the word itself\n",
    "{k: text_raw_dict[k] for k in list(text_raw_dict)[:5]}\n",
    "\n",
    "\n",
    "## Step 3: filter out very rare and very common words\n",
    "## here, i'm using the threshold that a word needs to appear in at least\n",
    "## 5% of docs but not more than 95%\n",
    "## this is an integer count of docs so i round\n",
    "lower_bound = round(fenty_df.shape[0]*0.05)\n",
    "upper_bound = round(fenty_df.shape[0]*0.95)\n",
    "\n",
    "### apply filtering to dictionary\n",
    "text_raw_dict.filter_extremes(no_below = lower_bound,\n",
    "                             no_above = upper_bound)\n",
    "print(f'Filtering out very rare and very common words reduced the \\\n",
    "length of dictionary from {str(raw_len)} to {str(len(text_raw_dict))}.')\n",
    "{k: text_raw_dict[k] for k in list(text_raw_dict)[:5]} # show first five entries after filtering\n",
    "\n",
    "\n",
    "## Step 4: apply dictionary to TOKENIZED texts\n",
    "## this creates a mapping between each word \n",
    "## in a specific listing and the key in the dictionary.\n",
    "## for words that remain in the filtered dictionary,\n",
    "## output is a list where len(list) == n documents\n",
    "## and each element in the list is a list of tuples\n",
    "## containing the mappings\n",
    "corpus_fromdict = [text_raw_dict.doc2bow(one_text) \n",
    "                   for one_text in text_raw_tokens]\n",
    "\n",
    "### can apply doc2bow(one_text, return_missing = True) to print words\n",
    "### eliminated from the listing bc they're not in filtered dictionary.\n",
    "### but feeding that one with missing values to\n",
    "### the lda function can cause errors\n",
    "corpus_fromdict_showmiss = [text_raw_dict.doc2bow(one_text, return_missing = True)\n",
    "                            for one_text in text_raw_tokens]\n",
    "print('Sample of documents represented in dictionary format (with omitted words noted):')\n",
    "corpus_fromdict_showmiss[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b9b15b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.models.ldamodel.LdaModel'>\n"
     ]
    }
   ],
   "source": [
    "## Step 5: we're finally ready to estimate the model!\n",
    "## full documentation here - https://radimrehurek.com/gensim/models/ldamodel.html\n",
    "## here, we're feeding the lda function:\n",
    "## (1) the corpus we created from the dictionary,\n",
    "## (2) a parameter we decide on for the number of topics (k),\n",
    "## (3) the dictionary itself,\n",
    "## (4) parameter for number of passes through training data (more means slower), and\n",
    "## (5) parameter that returns, for each word remaining in dict, the topic probabilities.\n",
    "## see documentation for many other arguments you can vary\n",
    "ldamod = gensim.models.ldamodel.LdaModel(corpus_fromdict, \n",
    "                                         num_topics = 5, \n",
    "                                         id2word=text_raw_dict, \n",
    "                                         passes=6, \n",
    "                                         alpha = 'auto',\n",
    "                                         per_word_topics = True)\n",
    "\n",
    "print(type(ldamod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6e60e7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.639*\"product\" + 0.234*\"foundat\" + 0.127*\"review\"')\n",
      "(1, '0.998*\"product\" + 0.001*\"foundat\" + 0.001*\"review\"')\n",
      "(2, '0.514*\"foundat\" + 0.478*\"review\" + 0.008*\"product\"')\n",
      "(3, '0.997*\"foundat\" + 0.002*\"product\" + 0.001*\"review\"')\n",
      "(4, '0.998*\"review\" + 0.001*\"foundat\" + 0.001*\"product\"')\n"
     ]
    }
   ],
   "source": [
    "## Post-model 1: explore corpus-wide summary of topics\n",
    "### getting the topics and top words; can retrieve diff top words\n",
    "topics = ldamod.print_topics(num_words = 10)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8df9616f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [mention, gloss, bomb, bright, fix, conceal, e...\n",
       "1                                                   []\n",
       "2    [everyon, review, first, impress, line, last, ...\n",
       "3    [make, sure, subscrib, channel, hit, notif, be...\n",
       "4    [die, get, hand, review, first, impress, line,...\n",
       "Name: cleaned_description, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[[(0, 0.16551188),\n",
       "  (1, 0.20902297),\n",
       "  (2, 0.17502663),\n",
       "  (3, 0.21745461),\n",
       "  (4, 0.23298393)],\n",
       " [(0, 0.16551188),\n",
       "  (1, 0.20902297),\n",
       "  (2, 0.17502663),\n",
       "  (3, 0.21745461),\n",
       "  (4, 0.23298393)],\n",
       " [(0, 0.083798826),\n",
       "  (1, 0.10582017),\n",
       "  (2, 0.08952449),\n",
       "  (3, 0.11008888),\n",
       "  (4, 0.6107676)],\n",
       " [(0, 0.16551188),\n",
       "  (1, 0.20902297),\n",
       "  (2, 0.17502663),\n",
       "  (3, 0.21745461),\n",
       "  (4, 0.23298393)],\n",
       " [(0, 0.08379882),\n",
       "  (1, 0.10582017),\n",
       "  (2, 0.089504845),\n",
       "  (3, 0.11008888),\n",
       "  (4, 0.61078733)]]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "## Post-model 2: explore topics associated with each document\n",
    "### for each item in our original dictionary, get list of topic probabilities\n",
    "l=[ldamod.get_document_topics(item) for item in corpus_fromdict]\n",
    "### print result\n",
    "text_raw_tokens[0:5]\n",
    "l[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4205a986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el3086157922857443331895972\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el3086157922857443331895972_data = {\"mdsDat\": {\"x\": [0.20951461849688752, 0.13853116350372088, -0.4340323675708901, 0.24346749141673868, -0.1574809058464574], \"y\": [-0.33794943331176913, 0.3447077677491519, -0.0536563684004737, 0.017831528356536275, 0.029066505606554233], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [31.598011293937866, 28.14466728783074, 24.747013425690444, 8.262588679975211, 7.2477193125657395]}, \"tinfo\": {\"Term\": [\"product\", \"review\", \"foundat\", \"review\", \"product\", \"foundat\", \"foundat\", \"product\", \"review\", \"product\", \"foundat\", \"review\", \"foundat\", \"review\", \"product\", \"product\", \"foundat\", \"review\"], \"Freq\": [267.0, 330.0, 308.0, 286.15696359236307, 0.20573382750310476, 0.2312670084586828, 254.6245506652091, 0.4439100899633806, 0.20368195298065306, 224.06782184450392, 0.1964048418946302, 0.19118596557384612, 38.50397377784104, 35.83566310355342, 0.6020476170347364, 41.976931406065304, 15.389771851731151, 8.370113177862905], \"Total\": [267.0, 330.0, 308.0, 330.7576077923339, 267.29644478507043, 308.9459681451346, 308.9459681451346, 267.29644478507043, 330.7576077923339, 267.29644478507043, 308.9459681451346, 330.7576077923339, 308.9459681451346, 330.7576077923339, 267.29644478507043, 267.29644478507043, 308.9459681451346, 330.7576077923339], \"Category\": [\"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [3.0, 2.0, 1.0, -0.0015, -7.2392, -7.1222, -0.0025, -6.3545, -7.1335, -0.0017, -7.0413, -7.0682, -0.6659, -0.7378, -4.8241, -0.4485, -1.452, -2.061], \"loglift\": [3.0, 2.0, 1.0, 1.0072, -6.0175, -6.0453, 1.0744, -5.1327, -6.1248, 1.2201, -5.9643, -6.0594, 0.411, 0.271, -3.6023, 0.7732, -0.375, -1.0522]}, \"token.table\": {\"Topic\": [2, 4, 5, 3, 4, 5, 1, 4, 5], \"Freq\": [0.825387045932277, 0.1262356658484659, 0.04855217917248688, 0.838020872967897, 0.0037411646114638257, 0.1571289136814807, 0.8646815470365993, 0.10884103389271879, 0.024186896420604176], \"Term\": [\"foundat\", \"foundat\", \"foundat\", \"product\", \"product\", \"product\", \"review\", \"review\", \"review\"]}, \"R\": 3, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 4, 2, 3, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el3086157922857443331895972\", ldavis_el3086157922857443331895972_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el3086157922857443331895972\", ldavis_el3086157922857443331895972_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el3086157922857443331895972\", ldavis_el3086157922857443331895972_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_display = gensimvis.prepare(ldamod, corpus_fromdict, text_raw_dict)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fc4291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nouns = [\n",
    "    word for one_tok in tokens_pos_list for (word, tag) in one_tok if tag == \"NNP\"\n",
    "]\n",
    "\n",
    "all_adj_and_nouns = [\n",
    "    word for one_tok in tokens_pos_list for (word, tag) in one_tok if tag == \"JJ\" or tag == \"NN\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ed6ccfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî† Top Proper Nouns: [('x', 97), ('_', 9), ('von', 6), ('kylie', 5), ('√†', 5), ('_the', 4), ('__', 4), ('youtuber', 3), ('‡§Æ', 3), ('makeup', 2), ('october', 2), ('Ìï®Íªò', 2), ('Ìïú', 2), ('Î∑∞Ìã∞', 2), ('ÌÜ†ÌÅ¨', 2), ('√©xito', 2), ('mattemoiselle', 2), ('‡§Æ‡§ï‡§¨', 2), ('‡§¨‡§ï‡§∏', 2), ('‡§∏‡§ä‡§¶', 2)]\n",
      "üí¨ Top Adjs/Nouns: [('fenty', 4195), ('beauty', 3628), ('rihanna', 1317), ('makeup', 1094), ('new', 1092), ('fentybeauty', 762), ('review', 752), ('i', 741), ('foundation', 726), ('skin', 709), ('video', 457), ('lip', 426), ('gloss', 424), ('bomb', 350), ('skincare', 334), ('first', 305), ('tutorial', 296), ('haul', 283), ('full', 282), ('amp', 276)]\n"
     ]
    }
   ],
   "source": [
    "# Top 20 most common proper nouns (e.g. brand names, product names)\n",
    "top_nouns = Counter(all_nouns).most_common(20)\n",
    "print(\"üî† Top Proper Nouns:\", top_nouns)\n",
    "\n",
    "# Top 20 adjectives and nouns (for common product features, sentiments)\n",
    "top_adj_nouns = Counter(all_adj_and_nouns).most_common(20)\n",
    "print(\"üí¨ Top Adjs/Nouns:\", top_adj_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "934914bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'huez',\n",
       " 'theyshe',\n",
       " 'castle',\n",
       " 'indianasian',\n",
       " 'tongue',\n",
       " 'shab',\n",
       " 'summer',\n",
       " 'plush',\n",
       " 'p',\n",
       " 'rockys',\n",
       " 'questionable',\n",
       " 'macchiato',\n",
       " 'criss',\n",
       " 'instinto',\n",
       " 'sight',\n",
       " 'muoka',\n",
       " 'lbs',\n",
       " 'impressionsreview',\n",
       " 'cl√£',\n",
       " 'iv',\n",
       " 'few',\n",
       " 'simiuk',\n",
       " 'usando',\n",
       " 'profilter',\n",
       " 'delight',\n",
       " 'avis',\n",
       " 'depth',\n",
       " 'agenda',\n",
       " 'hallo',\n",
       " 'interviewing',\n",
       " 'arianagrande',\n",
       " 'white',\n",
       " 'excellent',\n",
       " 'swarovski',\n",
       " 'news',\n",
       " 'empowerment',\n",
       " 'kay',\n",
       " 'blogger',\n",
       " 'crystal',\n",
       " 'weekly',\n",
       " 'contact',\n",
       " 'tense',\n",
       " 'shadowstix',\n",
       " 'monday',\n",
       " 'reviewer',\n",
       " 'sangria',\n",
       " 'unleash',\n",
       " 'sephorasale',\n",
       " 'forbes',\n",
       " 'freckle',\n",
       " 'comfortable',\n",
       " 'texturedacne',\n",
       " 'charitable',\n",
       " 'facebook',\n",
       " 'co',\n",
       " 'size',\n",
       " 'preppygrwm',\n",
       " 'sparkly',\n",
       " 'yan',\n",
       " 'aka',\n",
       " 'brightfix',\n",
       " 'kardashianjenner',\n",
       " 'edc',\n",
       " 'demi',\n",
       " 'balance',\n",
       " 'tom',\n",
       " 'kulfibeauty',\n",
       " 'valerian',\n",
       " 'redhead',\n",
       " 'nobie',\n",
       " 'banana',\n",
       " 'treslucebeauty',\n",
       " 'generous',\n",
       " 'ownit',\n",
       " 'jamaica',\n",
       " 'selfimage',\n",
       " 'anyone',\n",
       " 'affiliate',\n",
       " 'downright',\n",
       " 'travel',\n",
       " 'melissajackson',\n",
       " 'literal',\n",
       " 'boutique',\n",
       " 'further',\n",
       " 'raquel',\n",
       " 'lipsticklover',\n",
       " 'lunaglowbeauty',\n",
       " 'fentyholiday',\n",
       " 'hair',\n",
       " 'neva',\n",
       " 'film',\n",
       " 'success',\n",
       " 'lipscrub',\n",
       " 'software',\n",
       " 'hayley',\n",
       " 'awfrihanna',\n",
       " 'constant',\n",
       " 'colorism',\n",
       " 'quotuncensoredquot',\n",
       " 'pr',\n",
       " 'savagefenty',\n",
       " 'dog',\n",
       " 'notamment',\n",
       " 'storm',\n",
       " 'pov',\n",
       " 'incredible',\n",
       " 'hall',\n",
       " 'vee',\n",
       " 'forehead',\n",
       " 'smashbox',\n",
       " 'ysl',\n",
       " 'hiphopculture',\n",
       " 'phd',\n",
       " 'mediumtofull',\n",
       " 'monthly',\n",
       " 'foundationweartest',\n",
       " 'tester',\n",
       " 'winningquot',\n",
       " 'alisha',\n",
       " 'spree',\n",
       " 'form',\n",
       " 'pink',\n",
       " 'springsummer',\n",
       " 'tyrone',\n",
       " 'original',\n",
       " 'roblox',\n",
       " 'trend',\n",
       " 'shopmystash',\n",
       " 'intense',\n",
       " 'grammys',\n",
       " 'barbados',\n",
       " 'amazing',\n",
       " 'installment',\n",
       " 'diana',\n",
       " 'sono',\n",
       " 'sur',\n",
       " 'impression',\n",
       " 'fragrance',\n",
       " 'blushesmakeup',\n",
       " 'patch',\n",
       " 'relevant',\n",
       " 'maybelline',\n",
       " 'der',\n",
       " 'basketball',\n",
       " 'client',\n",
       " 'abode',\n",
       " 'hiphopfashion',\n",
       " 'newsletter',\n",
       " 'grandma',\n",
       " 'jelani',\n",
       " 'smiling',\n",
       " 'demiglow',\n",
       " 'tonof',\n",
       " 'std',\n",
       " 'lack',\n",
       " 'rum',\n",
       " 'dereon',\n",
       " 'underdawg',\n",
       " 'hyperglitz',\n",
       " 'tel',\n",
       " 'beautifier',\n",
       " 'arcane',\n",
       " 'genug',\n",
       " 'correct',\n",
       " 'trendy',\n",
       " 'tech',\n",
       " 'groundbreaking',\n",
       " 'lipbalm',\n",
       " 'ohemaa',\n",
       " 'final',\n",
       " 'hepaysattention',\n",
       " 'genderneutral',\n",
       " 'vanity',\n",
       " 'expresso',\n",
       " 'butta',\n",
       " 'sheinofficial',\n",
       " 'renee',\n",
       " 'lancomeukireland',\n",
       " 'flashback',\n",
       " 'panner',\n",
       " 'rundown',\n",
       " 'mvrubi',\n",
       " 'rhythms',\n",
       " 'welli',\n",
       " 'revolucionou',\n",
       " 'gardner',\n",
       " 'sauce',\n",
       " 'verb',\n",
       " 'hauls',\n",
       " 'renklerini',\n",
       " 'bar',\n",
       " 'placut',\n",
       " 'indepth',\n",
       " 'mature',\n",
       " 'ft',\n",
       " 'leomie',\n",
       " 'grammy',\n",
       " 'sacha',\n",
       " 'la',\n",
       " 'pt',\n",
       " 'pallet',\n",
       " 'mule',\n",
       " 'janaes',\n",
       " 'muse',\n",
       " 'modelo',\n",
       " 'mstopacjay',\n",
       " 'guru',\n",
       " 'gossip',\n",
       " 'fentycherry',\n",
       " 'point',\n",
       " 'hr',\n",
       " 'industryquot',\n",
       " 'veechanda',\n",
       " 'rihannabeauty',\n",
       " 'amazon',\n",
       " 'fui',\n",
       " 'morpheofficial',\n",
       " 'maquillaje',\n",
       " 'perfectskin',\n",
       " 'amberroseoatman',\n",
       " 'celebritygossip',\n",
       " 'kingston',\n",
       " 'makeupone',\n",
       " 'onfirst',\n",
       " 'roadtok',\n",
       " 'xpuma',\n",
       " 'borocz',\n",
       " 'las',\n",
       " 'mood',\n",
       " 'brightener',\n",
       " 'attack',\n",
       " 'beer',\n",
       " 'patience',\n",
       " 'makeupbytreenz',\n",
       " 'naturalmakeuplook',\n",
       " 'nbslive',\n",
       " 'cant',\n",
       " 'skintint',\n",
       " 'referencias',\n",
       " 'bmf',\n",
       " 'wash',\n",
       " 'afternoon',\n",
       " 'trust',\n",
       " 'fbmebeccamcavinue',\n",
       " 'curvy',\n",
       " 'charttoppinghitsit',\n",
       " 'rita',\n",
       " 'indemnity',\n",
       " 'powderblush',\n",
       " 'wasnt',\n",
       " 'pelenegra',\n",
       " 'blurringskintint',\n",
       " 'force',\n",
       " 'brandnew',\n",
       " 'star',\n",
       " 'wu',\n",
       " 'detail',\n",
       " 'eu',\n",
       " 'soft',\n",
       " 'cherry',\n",
       " 'maskmonday',\n",
       " 'quality',\n",
       " 'wealthy',\n",
       " 'mentor',\n",
       " 'gma',\n",
       " 'burnsurvivor',\n",
       " 'entertainment',\n",
       " 'process',\n",
       " 'thought',\n",
       " 'hugeee',\n",
       " 'candy',\n",
       " 'mercredi',\n",
       " 'text',\n",
       " 'social',\n",
       " 'serious',\n",
       " 'hill',\n",
       " 'nessa',\n",
       " 'sent',\n",
       " 'reality',\n",
       " 'friendly',\n",
       " 'charlottetilburybeautyshow',\n",
       " 'popular',\n",
       " 'illusion',\n",
       " 'blushlighter',\n",
       " 'tradu√ß√£o',\n",
       " 'khloekardashian',\n",
       " 'potential',\n",
       " 'value',\n",
       " 'plumping',\n",
       " 'fyptiktok',\n",
       " 'clean',\n",
       " 'correction',\n",
       " 'imagination',\n",
       " 'month',\n",
       " 'paulreactss',\n",
       " 'campaign',\n",
       " 'powderfoundation',\n",
       " 'beckham',\n",
       " 'future',\n",
       " 'strawberry',\n",
       " 'consultation',\n",
       " 'paloma',\n",
       " 'rihannainspiration',\n",
       " 'rater',\n",
       " 'dune',\n",
       " 'advent',\n",
       " 'con',\n",
       " 'makeupchallenge',\n",
       " 'silent',\n",
       " 'hbic',\n",
       " 'stuff',\n",
       " 'essencesephorahaul',\n",
       " 'areejz',\n",
       " 'apply',\n",
       " 'ahhh',\n",
       " 'genredefying',\n",
       " 'sarahpaulson',\n",
       " 'internet',\n",
       " 'garrette',\n",
       " 'ootd',\n",
       " 'khareeda',\n",
       " 'wetnwildbeauty',\n",
       " 'inside',\n",
       " 'prepping',\n",
       " 'epitome',\n",
       " 'sip',\n",
       " 'short',\n",
       " 'woo',\n",
       " 'little',\n",
       " 'secret',\n",
       " 'patrickta',\n",
       " 'swing',\n",
       " 'uploads',\n",
       " 'hit',\n",
       " 'major',\n",
       " 'cateyelook',\n",
       " 'grab',\n",
       " 'naima',\n",
       " 'quotrihanna',\n",
       " 'back',\n",
       " 'noche',\n",
       " 'theordinaryskincare',\n",
       " 'nurse',\n",
       " 'featuring',\n",
       " 'benefit',\n",
       " 'beautypagebychichi',\n",
       " 'zo√´',\n",
       " 'greasy',\n",
       " 'mane',\n",
       " 'beautyforeverybody',\n",
       " 'advance',\n",
       " 'quotfenty',\n",
       " 'madame',\n",
       " 'makeupfail',\n",
       " 'primark',\n",
       " 'rs',\n",
       " 'unstoppable',\n",
       " 'nickiminaj',\n",
       " 'berry',\n",
       " 'filter',\n",
       " 'jessica',\n",
       " 'crease',\n",
       " 'third',\n",
       " 'johnnyrossmakeup',\n",
       " 'primero',\n",
       " 'domination',\n",
       " 'trendingmakeup',\n",
       " 'blemish',\n",
       " 'mynykaa',\n",
       " 'fleshpot',\n",
       " 'tiny',\n",
       " 'emilysusanah',\n",
       " 'bawdy',\n",
       " 'kiyakarimu',\n",
       " 'quotneutralquot',\n",
       " 'theholiday',\n",
       " 'yall',\n",
       " 'milkmakeup',\n",
       " 'gamble',\n",
       " 'fentybeautys',\n",
       " 'brand',\n",
       " 'york',\n",
       " 'brazil',\n",
       " 'valuable',\n",
       " 'anticipate',\n",
       " 'twittercomalvajvelasco',\n",
       " 'real',\n",
       " 'deedee',\n",
       " 'sl',\n",
       " 'luminiser',\n",
       " 'description',\n",
       " 'relatable',\n",
       " 'bianca',\n",
       " 'byron',\n",
       " 'col√©',\n",
       " 'robert',\n",
       " 'pumpkin',\n",
       " 'air',\n",
       " 'posse',\n",
       " 'lifetime',\n",
       " 'earth',\n",
       " 'glittergloss',\n",
       " 'deluxe',\n",
       " 'flexible',\n",
       " 'payoff',\n",
       " 'nea',\n",
       " 'guidance',\n",
       " 'wifeshortvideo',\n",
       " 'rihannaaap',\n",
       " 'purpleblush',\n",
       " 'fyp„Ç∑',\n",
       " 'albino',\n",
       " 'hero',\n",
       " 'tape',\n",
       " 'armon',\n",
       " 'ad',\n",
       " 'hiya',\n",
       " 'privilege',\n",
       " 'own',\n",
       " 'remarkable',\n",
       " 'period',\n",
       " 'lauder',\n",
       " 'mic',\n",
       " 'cccb',\n",
       " 'ya',\n",
       " 'nude',\n",
       " 'alliwantforchristmasisyou',\n",
       " 'allll',\n",
       " 'betta',\n",
       " 'rico',\n",
       " 'evening',\n",
       " 'fentyface',\n",
       " 'cup',\n",
       " 'moon',\n",
       " 'lane',\n",
       " 'statement',\n",
       " 'universali',\n",
       " 'carnegie',\n",
       " 'alexis',\n",
       " 'stick',\n",
       " 'authenticity',\n",
       " 'glossier',\n",
       " 'stellar',\n",
       " 'stash',\n",
       " 'rise',\n",
       " 'aesthetic',\n",
       " 'chopras',\n",
       " 'related',\n",
       " 'sid_chiin',\n",
       " 'routinefenty',\n",
       " 'mediumtan',\n",
       " 'poser',\n",
       " 'il',\n",
       " 'thankful',\n",
       " 'chill',\n",
       " 'shimmerstixvsoil',\n",
       " 'ooo',\n",
       " 'pale',\n",
       " 'umm',\n",
       " 'customization',\n",
       " 'piece',\n",
       " 'mois',\n",
       " 'shape',\n",
       " 'rihannaasap',\n",
       " 'fail',\n",
       " 'jayson',\n",
       " 'request',\n",
       " 'figaro',\n",
       " 'fruity',\n",
       " 'disclaimer',\n",
       " 'list',\n",
       " 'spoiler',\n",
       " 'pre',\n",
       " 'recevoir',\n",
       " 'racial',\n",
       " 'newvideo',\n",
       " 'enterpreneur',\n",
       " 'nouveaut√©',\n",
       " 'lewis',\n",
       " 'nuance',\n",
       " 'game',\n",
       " 'work',\n",
       " 'review',\n",
       " 'missionfentybeauty',\n",
       " 'tip',\n",
       " 'newwwrarebeauty',\n",
       " 'perfection',\n",
       " 'parfum',\n",
       " 'wish',\n",
       " 'da',\n",
       " 'lvmhowned',\n",
       " 'juna',\n",
       " 'estee',\n",
       " 'faire',\n",
       " 'jaguar',\n",
       " 'resilience',\n",
       " 'laurent',\n",
       " 'lk',\n",
       " 'boy',\n",
       " 'maquillage',\n",
       " 'aber',\n",
       " 'fluid',\n",
       " 'heart',\n",
       " 'grahamnorton',\n",
       " 'cardib',\n",
       " 'online',\n",
       " 'darkskin',\n",
       " 'thatll',\n",
       " 'vizor',\n",
       " 'marque',\n",
       " 'ballerini',\n",
       " 'jazmin',\n",
       " 'goodiesss',\n",
       " 'flannery',\n",
       " 'havent',\n",
       " 'dotti',\n",
       " 'nuestra',\n",
       " 'infallible',\n",
       " 'proffesional',\n",
       " 'wax',\n",
       " 'gen',\n",
       " 'thespnation',\n",
       " 'killawat',\n",
       " 'page',\n",
       " 'character',\n",
       " 'unforgettable',\n",
       " 'beautys',\n",
       " 'pocaboriginalfirst',\n",
       " 'band',\n",
       " 'africa',\n",
       " 'fullon',\n",
       " 'tag',\n",
       " 'trabajar',\n",
       " 'combination',\n",
       " 'paypalrobinstikeanedu',\n",
       " 'scholar',\n",
       " 'ha',\n",
       " 'aye',\n",
       " 'sigh',\n",
       " 'financialliteracy',\n",
       " 'stunning',\n",
       " 'pas',\n",
       " 'driverquot',\n",
       " 'level',\n",
       " 'fentylaunch',\n",
       " 'melt',\n",
       " 'caramel',\n",
       " 'contentcreator',\n",
       " 'genesiss',\n",
       " 'crem',\n",
       " 'damage',\n",
       " 'tried',\n",
       " 'reshae',\n",
       " 'lipcolour',\n",
       " 'met',\n",
       " 'rhenna',\n",
       " 'sidiachin',\n",
       " 'content',\n",
       " 'dutchess',\n",
       " 'chega',\n",
       " 'mentality',\n",
       " 'namibia',\n",
       " 'house',\n",
       " 'fall',\n",
       " 'makeuptryon',\n",
       " 'faux',\n",
       " 'covergirl',\n",
       " 'nail',\n",
       " 'kendracus',\n",
       " 'join',\n",
       " 'goodbye',\n",
       " 'yt',\n",
       " 'sephorasquad',\n",
       " 'tool',\n",
       " 'cinnamon',\n",
       " 'childhood',\n",
       " 'suade',\n",
       " 'rest',\n",
       " 'ny',\n",
       " 'onehit',\n",
       " 'gown',\n",
       " 'enlightening',\n",
       " 'immallorybrooke',\n",
       " 'turning',\n",
       " 'hoola',\n",
       " 'dermalogica',\n",
       " 'big',\n",
       " 'eazey',\n",
       " 'plenty',\n",
       " 'prtylittlesyko',\n",
       " 'infamous',\n",
       " 'dernier',\n",
       " 'mvpquot',\n",
       " 'kelsea',\n",
       " 'formula',\n",
       " 'lippie',\n",
       " 'combat',\n",
       " 'illuminator',\n",
       " 'exclusive',\n",
       " 'christiane',\n",
       " 'unique',\n",
       " 'hasnt',\n",
       " 'first',\n",
       " 'makeuplover',\n",
       " 'rihanna',\n",
       " 'comedy',\n",
       " 'myesha',\n",
       " 'hyaluronic',\n",
       " 'showon',\n",
       " 'blog',\n",
       " 'approach',\n",
       " 'help',\n",
       " 'bishop',\n",
       " 'alexpavlova',\n",
       " 'streetwear',\n",
       " 'stress',\n",
       " 'inequality',\n",
       " 'happiness',\n",
       " 'transition',\n",
       " 'mericier',\n",
       " 'niko',\n",
       " 'raisin',\n",
       " 'fentybeautymakeupskincarelipbalmlipmaskrihannapinkmakeupsephoraultahaul',\n",
       " 'fentyskintint',\n",
       " 'associate',\n",
       " 'try',\n",
       " 'continuespeak',\n",
       " 'lisaj',\n",
       " 'eazedroplit',\n",
       " 'smurfs',\n",
       " 'sunkissed',\n",
       " 'loved',\n",
       " 'reviewswatchdemo',\n",
       " 'zodiac',\n",
       " 'bubble',\n",
       " 'deola',\n",
       " 'lorealparisusa',\n",
       " 'mattetallic',\n",
       " 'side',\n",
       " 'sheglamvideo',\n",
       " 'transformational',\n",
       " 'liner',\n",
       " 'mauve',\n",
       " 'foryou',\n",
       " 'taylortribe',\n",
       " 'viralvideos',\n",
       " 'non',\n",
       " 'versatile',\n",
       " 'bbc',\n",
       " 'crashtest',\n",
       " 'chantel',\n",
       " 'fruityfloral',\n",
       " 'touch',\n",
       " 'system',\n",
       " '√†',\n",
       " 'glamzilla',\n",
       " 'plussize',\n",
       " 'salty',\n",
       " 'yu',\n",
       " 'paint',\n",
       " 's',\n",
       " 'mememonroe',\n",
       " 'food',\n",
       " 'brunch',\n",
       " 'unlocked',\n",
       " 'editor',\n",
       " 'mikara',\n",
       " 'hydratingserum',\n",
       " 'kassie',\n",
       " 'alexander',\n",
       " 'tiktokmagic',\n",
       " 'josephine',\n",
       " 'boxycharm',\n",
       " 'weight',\n",
       " 'diff',\n",
       " 'advanced',\n",
       " 'hellooooooo',\n",
       " 'latch',\n",
       " 'rained',\n",
       " 'rihannafenty',\n",
       " 'elevating',\n",
       " 'cota',\n",
       " 'projectan',\n",
       " 'advertising',\n",
       " 'newlaunch',\n",
       " 'twitch',\n",
       " 'speechless',\n",
       " 'detroit',\n",
       " 'smileline',\n",
       " 'jesswyattmakeup',\n",
       " 'kaisercoby',\n",
       " 'fentybeautylipcombo',\n",
       " 'mais',\n",
       " 'kon',\n",
       " 'blurring',\n",
       " 'love',\n",
       " 'colourtheory',\n",
       " 'hudabeautyshop',\n",
       " 'crush',\n",
       " 'badgalriri',\n",
       " 'aqua',\n",
       " 'current',\n",
       " 'droplit',\n",
       " 'rebekah',\n",
       " 'bingemoscow',\n",
       " 'startrs',\n",
       " 'purplelipoil',\n",
       " 'hudabeauty',\n",
       " 'isan',\n",
       " 'simplydemi',\n",
       " 'nikitakarizma',\n",
       " 'colourpop',\n",
       " 'druskis',\n",
       " 'artificial',\n",
       " 'laptop',\n",
       " 'makeupbysisi',\n",
       " 'coconut',\n",
       " 'surrealskin',\n",
       " 'morracan',\n",
       " 'tune',\n",
       " 'pigment',\n",
       " 'kardashian',\n",
       " 'chic',\n",
       " 'raine',\n",
       " 'jazlmao',\n",
       " 'lipmask',\n",
       " 'creme',\n",
       " 'matifiante',\n",
       " 'fencygrace',\n",
       " 'intro',\n",
       " 'exhausted',\n",
       " 'rocnation',\n",
       " 'unlock',\n",
       " 'hormozi',\n",
       " 'beautyboxen',\n",
       " 'beauy',\n",
       " 'exfoliating',\n",
       " 'sinamon',\n",
       " 'jparmarmakeup',\n",
       " 'maxx',\n",
       " 'latte',\n",
       " 'smurfette',\n",
       " 'supermodel',\n",
       " 'makeover',\n",
       " 'facialcleanser',\n",
       " 'tint',\n",
       " 'og',\n",
       " 'yoooo',\n",
       " 'bunch',\n",
       " 'flashing',\n",
       " 'intuitive',\n",
       " 'desc',\n",
       " 'luxe',\n",
       " 'insta',\n",
       " 'last',\n",
       " 'project',\n",
       " 'robe',\n",
       " 'welp',\n",
       " 'wont',\n",
       " 'blonde',\n",
       " 'tantour',\n",
       " 'stix',\n",
       " 'bullsht',\n",
       " 'fav',\n",
       " 'traumatic',\n",
       " 'ginger',\n",
       " 'disabled',\n",
       " 'buttadrop',\n",
       " 'rid',\n",
       " 'wit',\n",
       " 'calendrier',\n",
       " 'sophiebbeauty',\n",
       " 'fauxfilter',\n",
       " 'attention',\n",
       " 'urban',\n",
       " 'sorry',\n",
       " 'retro',\n",
       " 'mahalia',\n",
       " 'mahogany',\n",
       " 'beautybay',\n",
       " '_____',\n",
       " 'puckerupbabe',\n",
       " 'metropolis',\n",
       " 'marble',\n",
       " 'whole',\n",
       " 'hai',\n",
       " 'sont',\n",
       " 'serum',\n",
       " 'los',\n",
       " 'entire',\n",
       " 'identity',\n",
       " 'thats',\n",
       " 'debut',\n",
       " 'millionaire',\n",
       " 'moisture',\n",
       " 'laeno',\n",
       " 'bailey',\n",
       " 'tang',\n",
       " 'eye',\n",
       " 'tone',\n",
       " 'retouch',\n",
       " 'clarify',\n",
       " 'press',\n",
       " 'revealrihanna',\n",
       " 'deux',\n",
       " 'disability',\n",
       " 'ent√©rate',\n",
       " 'halftimeshow',\n",
       " 'sheher',\n",
       " 'garnier',\n",
       " 'tamar',\n",
       " 'subscribed',\n",
       " 'recap',\n",
       " 'sblvii',\n",
       " 'winstonduke',\n",
       " 'kkw',\n",
       " 'echipa',\n",
       " 'destination',\n",
       " 'september',\n",
       " 'matteprimer',\n",
       " 'iman',\n",
       " 'science',\n",
       " 'gary',\n",
       " 'deppscarlett',\n",
       " 'superbowllvii',\n",
       " 'sunday',\n",
       " 'creamy',\n",
       " 'road',\n",
       " 'inscrevam',\n",
       " 'abundance',\n",
       " 'behindthescenes',\n",
       " 'iÃánterview',\n",
       " 'army',\n",
       " 'diamondbomb',\n",
       " 'lamonicas',\n",
       " 'lit',\n",
       " 'patrick',\n",
       " 'iammagiccollection',\n",
       " 'hud',\n",
       " 'brownskinmakeup',\n",
       " 'yslbeautyofficial',\n",
       " 'comfy',\n",
       " 'mary',\n",
       " 'thingstodoinatlanta',\n",
       " 'kel',\n",
       " 'danessa',\n",
       " 'apart',\n",
       " 'ill',\n",
       " 'primor',\n",
       " 'meilleure',\n",
       " 'memory',\n",
       " 'daytonight',\n",
       " 'lipglossworth',\n",
       " 'tarte',\n",
       " 'chandler',\n",
       " 'performance',\n",
       " 'ash',\n",
       " 'chance',\n",
       " 'mensroutine',\n",
       " 'brasil',\n",
       " 'stage',\n",
       " 'paid',\n",
       " 'awkward',\n",
       " 'ink',\n",
       " 'getrightodt',\n",
       " 'ph',\n",
       " 'mediahub',\n",
       " 'communication',\n",
       " 'send',\n",
       " 'philanthropy',\n",
       " 'funny',\n",
       " 'fix',\n",
       " 'fentyparfum',\n",
       " 'spotify',\n",
       " 'alexandre',\n",
       " 'crash',\n",
       " 'el',\n",
       " 'settingspray',\n",
       " 'teresa',\n",
       " 'samelias',\n",
       " 'ashortaday',\n",
       " 'successstory',\n",
       " 'gibson',\n",
       " 'addiction',\n",
       " 'feature',\n",
       " 'embrace',\n",
       " 'cox',\n",
       " 'sephoravibsale',\n",
       " 'ashleisure',\n",
       " 'great',\n",
       " 'fambam',\n",
       " 'autumn',\n",
       " 'tok',\n",
       " 'armani',\n",
       " 'revolutionary',\n",
       " 'portfolio',\n",
       " 'tonight',\n",
       " 'store',\n",
       " 'haulvideo',\n",
       " 'likely',\n",
       " 'elsesser',\n",
       " 'premium',\n",
       " 'camera',\n",
       " 'rachelocool',\n",
       " 'makeupvideo',\n",
       " 'homechef',\n",
       " '‡§Ü‡§ú',\n",
       " 'wantd',\n",
       " 'fear',\n",
       " 'bomb',\n",
       " 'stylerihanna',\n",
       " 'intentional',\n",
       " 'waldron',\n",
       " 'questo',\n",
       " 'fuschia',\n",
       " 'quotthick',\n",
       " 'class',\n",
       " 'massive',\n",
       " 'thi',\n",
       " 'pronunciation',\n",
       " 'creatorpreneur',\n",
       " 'selenagomez',\n",
       " 'karma',\n",
       " 'shop',\n",
       " 'martine',\n",
       " 'squad',\n",
       " 'fancy',\n",
       " 'blackout',\n",
       " 'opionion',\n",
       " 'fentybeautybrightfixconcealerpumpkin',\n",
       " 'tanigarchas',\n",
       " 'addictive',\n",
       " 'luminizer',\n",
       " 'k',\n",
       " 'raynne',\n",
       " 'hunny',\n",
       " 'browngirl',\n",
       " 'periperaofficialusa',\n",
       " 'application',\n",
       " 'bite',\n",
       " 'kendalljenner',\n",
       " 'dynamic',\n",
       " 'ihr',\n",
       " 'icy',\n",
       " 'supa',\n",
       " 'total',\n",
       " 'alternative',\n",
       " 'fill',\n",
       " 'ndeyepeinda',\n",
       " 'australia',\n",
       " 'different',\n",
       " 'editado',\n",
       " 'ring',\n",
       " 'pbampj',\n",
       " 'increible',\n",
       " 'high',\n",
       " 'tinted',\n",
       " 'fruit',\n",
       " 'eau',\n",
       " 'walker',\n",
       " 'oneyear',\n",
       " 'Î¶¨ÌïúÎÇòÏóêÍ≤å',\n",
       " 'givin',\n",
       " 'pda',\n",
       " 'click',\n",
       " 'faisa',\n",
       " 'multitasking',\n",
       " 'admiration',\n",
       " 'd√©couvrez',\n",
       " 'birthday',\n",
       " 'scarlettdepphotmailcom',\n",
       " 'beautywhich',\n",
       " 'thrifting',\n",
       " 'lifter',\n",
       " 'jacket',\n",
       " 'toner',\n",
       " 'charlottetilbury',\n",
       " 'dry',\n",
       " 'service',\n",
       " 'ishh',\n",
       " 'wedding',\n",
       " 'prettylittlesykogmailcom',\n",
       " 'tour',\n",
       " 'note',\n",
       " 'globalquot',\n",
       " 'goss',\n",
       " 'kaseyrayton',\n",
       " 'jasmine',\n",
       " 'neutral',\n",
       " 'taking',\n",
       " 'shortsviral',\n",
       " 'lindo',\n",
       " 'recorddeal',\n",
       " 'response',\n",
       " 'epic',\n",
       " 'imovie',\n",
       " 'comparaison',\n",
       " 'rubiitofficial',\n",
       " 'flower',\n",
       " 'reviewbeauty',\n",
       " ...}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1adea5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand videos: 153\n",
      "Influencer videos: 547\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c54acfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('fentybeauty', 193), ('rihanna', 164), ('gloss', 154), ('new', 152), ('bomb', 119), ('makeup', 112), ('lip', 107), ('s', 92), ('foundation', 84), ('stix', 75), ('review', 63), ('skin', 56), ('soft', 48), ('swatches', 45), ('amp', 44), ('lipstick', 40), ('lit', 37), ('shade', 35), ('sephora', 35), ('powder', 31)]\n"
     ]
    }
   ],
   "source": [
    "all_words = ' '.join(df['title'].dropna()).lower()\n",
    "words = re.findall(r'\\b[a-z]+\\b', all_words)\n",
    "word_counts = Counter(words)\n",
    "\n",
    "# Most common non-boring words\n",
    "common = [w for w in word_counts.items() if w[0] not in {'the','and','with','for','of','to','in', 'by', 'shorts', 'is', 'fenty','beauty'}]\n",
    "print(sorted(common, key=lambda x: x[1], reverse=True)[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13a7d403",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags = pos_tag(words)\n",
    "for word, pos_tag in pos_tags:\n",
    "    print(f\"{word}: {pos_tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436d8a99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qss-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
