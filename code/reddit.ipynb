{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit Scraping\n",
    "Documentation reference: https://praw.readthedocs.io/en/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import praw\n",
    "from praw.models import MoreComments\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import ast\n",
    "import re\n",
    "# Tools for text analysis\n",
    "# We can use nltk to extract adjective and verbs related to the product/brand \n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "# Vader sentiment analysis \n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "os.makedirs(\"../output\", exist_ok=True)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape post from related subreddits\n",
    "Usage: Consumer sentiment analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=os.getenv(\"REDDIT_CLIENT_ID\"),\n",
    "    client_secret=os.getenv(\"REDDIT_CLIENT_SECRET\"),\n",
    "    user_agent=os.getenv(\"REDDIT_USER_AGENT\"),\n",
    "    username=os.getenv(\"REDDIT_USERNAME\"),\n",
    ")\n",
    "\n",
    "# \"Skincare_Addiction\", \"asianskincare\", \"Blackskincare\",\"SkincareAddicts\"\n",
    "subreddit_list = [\"SkincareAddiction\",]\n",
    "\n",
    "all_posts = []\n",
    "\n",
    "# get the top 20 post from each subreddit (don't know rate limit so 20 for now)\n",
    "# Documentation: https://praw.readthedocs.io/en/stable/code_overview/models/subreddit.html\n",
    "all_brands = ['Estée Lauder',\n",
    "'Fenty Beauty (by Rihanna)',\n",
    "'e.l.f. Cosmetics',\n",
    "'Tarte Cosmetics',\n",
    "'Glossier',\n",
    "'Laneige',\n",
    "'Sulwhasoo',\n",
    "'Etude House',\n",
    "'Innisfree',\n",
    "'COSRX',\n",
    "]\n",
    "\n",
    "def is_bot(author):\n",
    "    if author is None:\n",
    "        return True\n",
    "    name = author.name.lower()\n",
    "    return \"bot\" in name or name == \"automoderator\"\n",
    "\n",
    "def get_top_comments(post):\n",
    "\n",
    "    post.comments.replace_more(limit=0)  \n",
    "\n",
    "    top_comments = []\n",
    "    for comment in post.comments:\n",
    "        if isinstance(comment, MoreComments):\n",
    "            continue \n",
    "        if is_bot(comment.author):\n",
    "            continue\n",
    "        if comment.body.strip().lower() in [\"[deleted]\", \"[removed]\"]:\n",
    "            continue \n",
    "        top_comments.append(comment.body.strip())\n",
    "        if len(top_comments) == 5:\n",
    "            break\n",
    "    return top_comments\n",
    "        \n",
    "for sub in subreddit_list:\n",
    "    try:\n",
    "        for brand in all_brands:\n",
    "            query = f'\"{brand}\"'\n",
    "            post_collection = reddit.subreddit(sub).search(query, limit=20)  \n",
    "            for post in post_collection: \n",
    "                top_comments = get_top_comments(post)\n",
    "                all_posts.append({\n",
    "                \"subreddit_name\": sub,\n",
    "                \"post_id\": post.id,\n",
    "                \"title\": post.title,\n",
    "                \"description\": post.selftext,\n",
    "                \"score\": post.score,\n",
    "                \"num_comments\": post.num_comments,\n",
    "                \"top_comments\": top_comments,\n",
    "                \"upvote_ratio\": post.upvote_ratio,\n",
    "                \"brand\": brand\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {sub}: {e}\")\n",
    "        continue\n",
    "    \n",
    "subreddit_df = pd.DataFrame(all_posts)\n",
    "subreddit_df\n",
    "subreddit_df.to_csv(\"../output/subreddit_data.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comment text cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['skin looks great best part picture smile',\n",
       " 'daily routine use pumps clinique take day cleansing oil purple bottle rub face product used skin types oily friends need worry wash oil face warm wash cloth wash face caress daily silk beauty bar regular ol bar soap really cleanses skin gentle dry face towel put two drops estée lauder advanced night repair face little bit goes longgggg way plus try conserve due priciness product rubbed let sit dry kinda tacky feel put dime half dry skin feel skin needs dime lol sunday riley tidal cream repeat step night well skin type since using products mostly normal dry patches appearing exfoliated exfoliate every days using skin medica exfoliating cleanser questions let know love answer edit use kiehl super fluid daily uv defense sunscreen spf face advanced night repair serum applying tidal cream sunscreen bit ashy skin complexion great suggestions sunscreens could use would awesome sorry left',\n",
       " 'looks pretty',\n",
       " 'gorgeous also stunning smile girl',\n",
       " 'beautiful happy bubbly pic comments enthusiasm contagious thanks making day better wonderful']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skincare_df = pd.read_csv(\"../output/subreddit_data.csv\")\n",
    "skincare_df[\"top_comments\"] = skincare_df[\"top_comments\"].apply(ast.literal_eval)\n",
    "# make it a bit more readable, need do More cleaning for sentiment analysis \n",
    "skincare_df[\"top_comments\"][0]\n",
    "\n",
    "custom_stopwords = []\n",
    "stopword_set = set(nltk_stopwords.words('english')).union(custom_stopwords)\n",
    "# stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def preprocess_comment(comment):\n",
    "    comment_lower = comment.lower()\n",
    "    tokens = word_tokenize(comment_lower)\n",
    "    filtered_tokens = [t for t in tokens if t.isalpha() and t not in stopwords]\n",
    "    return \" \".join(filtered_tokens)\n",
    "\n",
    "skincare_df[\"cleaned_comments\"] = skincare_df[\"top_comments\"].apply(\n",
    "    lambda comments: [preprocess_comment(c) for c in comments]\n",
    ")\n",
    "\n",
    "skincare_df[\"cleaned_comments\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comment analysis\n",
    "\n",
    "The post are searched by keywords, however within each post various brands are mentioned. \n",
    "Thinking of breaking comment into rows and tag by directly related brands and its sentiment score and keep search_term as brand search reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.value_counts of      post_id                                            comment  \\\n",
       "0     8qkw0m  Your skin looks great but the best part of thi...   \n",
       "1     8qkw0m  Here is my Daily Routine:\\n\\nIn the AM/PM\\n1.)...   \n",
       "2     8qkw0m                                   Looks SO pretty!   \n",
       "3     8qkw0m  Gorgeous! You also have such a stunning smile,...   \n",
       "4     8qkw0m  You are so beautiful and happy and bubbly in t...   \n",
       "..       ...                                                ...   \n",
       "507  1hzmf86  I love this cleanser. Very gentle and super mo...   \n",
       "508  1jl202e  Is it only during the day time and not after y...   \n",
       "509  1jl202e  Do you use any sort of occlusive at night? I a...   \n",
       "510  1iytc6q  No one will be able to tell you for sure, it's...   \n",
       "511  1iytc6q  https://preview.redd.it/yafvwf56tile1.jpeg?wid...   \n",
       "\n",
       "    brand_mentioned   search_term          subreddit  sentiment_score  \\\n",
       "0              None  Estée Lauder  SkincareAddiction           0.9168   \n",
       "1      Estée Lauder  Estée Lauder  SkincareAddiction           0.9789   \n",
       "2              None  Estée Lauder  SkincareAddiction           0.6724   \n",
       "3              None  Estée Lauder  SkincareAddiction           0.9133   \n",
       "4              None  Estée Lauder  SkincareAddiction           0.9663   \n",
       "..              ...           ...                ...              ...   \n",
       "507            None         COSRX  SkincareAddiction           0.9344   \n",
       "508            None         COSRX  SkincareAddiction           0.0000   \n",
       "509            None         COSRX  SkincareAddiction           0.3612   \n",
       "510            None         COSRX  SkincareAddiction           0.1280   \n",
       "511            None         COSRX  SkincareAddiction           0.0000   \n",
       "\n",
       "    sentiment_label  \n",
       "0          positive  \n",
       "1          positive  \n",
       "2          positive  \n",
       "3          positive  \n",
       "4          positive  \n",
       "..              ...  \n",
       "507        positive  \n",
       "508         neutral  \n",
       "509        positive  \n",
       "510        positive  \n",
       "511         neutral  \n",
       "\n",
       "[512 rows x 7 columns]>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer() \n",
    "comment_rows = []\n",
    "\n",
    "\n",
    "# Search for mentioning of brand value ?\n",
    "# tagging brand to the comment and getting the sentiment score\n",
    "for _,row in skincare_df.iterrows():\n",
    "    for comment in row[\"top_comments\"]:\n",
    "        comment_lower = comment.lower()\n",
    "        mentioned_brands = [b for b in all_brands if re.search(rf\"\\b{re.escape(b.lower())}\\b\", comment_lower)]\n",
    "        if not mentioned_brands:\n",
    "            mentioned_brands = [\"None\"]\n",
    "        for brand in mentioned_brands:\n",
    "            sentiment_score = analyzer.polarity_scores(comment)[\"compound\"]\n",
    "            sentiment_label = (\n",
    "                \"positive\" if sentiment_score > 0.05\n",
    "                else \"negative\" if sentiment_score < -0.05\n",
    "                else \"neutral\"\n",
    "            )\n",
    "            comment_rows.append({\n",
    "                \"post_id\": row[\"post_id\"],\n",
    "                \"comment\": comment,\n",
    "                \"brand_mentioned\": brand,\n",
    "                \"search_term\": row[\"brand\"],\n",
    "                \"subreddit\": row[\"subreddit_name\"],\n",
    "                \"sentiment_score\": sentiment_score,\n",
    "                \"sentiment_label\": sentiment_label\n",
    "            })\n",
    "comment_df = pd.DataFrame(comment_rows)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qss-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
